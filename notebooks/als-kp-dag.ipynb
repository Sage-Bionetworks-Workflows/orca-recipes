{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c6355f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIRFLOW__SECRETS__BACKENDS set.\n",
      "AIRFLOW_CONN_SYNAPSE_ORCA_SERVICE_ACCOUNT_CONN set.\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "\n",
    "# 1) Use env-var secrets backend instead of the metastore\n",
    "os.environ[\"AIRFLOW__SECRETS__BACKENDS\"] = \"airflow.secrets.env_vars.EnvVarSecretsBackend\"\n",
    "\n",
    "# 2) Provide the connection your DAG expects via env var\n",
    "#    Conn ID: SYNAPSE_ORCA_SERVICE_ACCOUNT_CONN  (from your code)\n",
    "\n",
    "# Put your real creds in these env vars (or hardcode here for local testing)\n",
    "SYN_USER = os.environ.get(\"SYN_USER\", \"ramayyala\")\n",
    "SYN_PAT  = os.environ.get(\"SYN_PAT\",  \"eyJ0eXAiOiJKV1QiLCJraWQiOiJXN05OOldMSlQ6SjVSSzpMN1RMOlQ3TDc6M1ZYNjpKRU9VOjY0NFI6VTNJWDo1S1oyOjdaQ0s6RlBUSCIsImFsZyI6IlJTMjU2In0.eyJhY2Nlc3MiOnsic2NvcGUiOlsidmlldyIsImRvd25sb2FkIiwibW9kaWZ5Il0sIm9pZGNfY2xhaW1zIjp7fX0sInRva2VuX3R5cGUiOiJQRVJTT05BTF9BQ0NFU1NfVE9LRU4iLCJpc3MiOiJodHRwczovL3JlcG8tcHJvZC5wcm9kLnNhZ2ViYXNlLm9yZy9hdXRoL3YxIiwiYXVkIjoiMCIsIm5iZiI6MTc1MDEzOTQxMiwiaWF0IjoxNzUwMTM5NDEyLCJqdGkiOiIyMTc2NyIsInN1YiI6IjM0MzY2NjYifQ.faAoqrFfcsQysDQkhvGCPQw54yN84rAJkXSDh6v8kYz4Yi6jU9F5U3V57cUthtHTKkeqLK1-XkVI8OJ2_QeQ_IUW6W2gTgt0ATH6YHsFroQkysbfcF1BnddG9_mWeX2dl5bvz0xbwSUPJYc9LVd-Nj-GvljjYdcHumeskCKYUfj5VjgwBMQS_Qw7BG1a9krcONyv3RBPk7AVYskk1ptoNBrHafjGpqfN5-8RVtetQQKgztpyFGwgDEONTrL52Y3JxzKQAOFmmWtSrEqRNmZxmeLh4C5RTkhnc5gE3o1Fd-uCi1bOkImAFyHppCsq9zsPQYUGkuUrFFrD76YBUdJL1A\")\n",
    "\n",
    "# Airflow supports JSON-style connection definitions in env vars\n",
    "airflow_conn_json = {\n",
    "    #\"conn_id\":   \"SYNAPSE_ORCA_SERVICE_ACCOUNT_CONN\",\n",
    "    \"conn_type\": \"http\",  # type is largely ignored by your custom hook; http is fine\n",
    "    \"host\":      \"https://repo-prod.prod.sagebase.org\",\n",
    "    \"login\":     SYN_USER,\n",
    "    \"password\":  SYN_PAT,\n",
    "    # If your SynapseHook reads extras, you can add them here:\n",
    "    \"extra\": {\"profile\": \"service-account\"}\n",
    "}\n",
    "\n",
    "os.environ[\"AIRFLOW_CONN_SYNAPSE_ORCA_SERVICE_ACCOUNT_CONN\"] = json.dumps(airflow_conn_json)\n",
    "\n",
    "print(\"AIRFLOW__SECRETS__BACKENDS set.\")\n",
    "print(\"AIRFLOW_CONN_SYNAPSE_ORCA_SERVICE_ACCOUNT_CONN set.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caada532",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import requests\n",
    "from typing import Dict, List, Tuple, Any, Optional\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "from jsonata import jsonata\n",
    "from jsonschema import validate, ValidationError\n",
    "\n",
    "from synapseclient.models import Dataset, DatasetCollection, File\n",
    "from orca.services.synapse import SynapseHook\n",
    "import synapseclient \n",
    "from airflow.decorators import task, dag\n",
    "from airflow.models import Variable, Param\n",
    "from slack_sdk import WebClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "243873e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2025-10-08T23:29:03.523+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1026} INFO\u001b[0m - HTTP Request: GET https://pypi.org/pypi/synapseclient/json \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "Welcome, ram.ayyala!\n",
      "\n",
      "[\u001b[34m2025-10-08T23:29:03.636+0000\u001b[0m] {\u001b[34mclient.py:\u001b[0m1014} INFO\u001b[0m - Welcome, ram.ayyala!\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "syn = synapseclient.Synapse()\n",
    "syn.login(authToken=SYN_PAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20f9eb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "dag_params = {\n",
    "    \"project_id\": Param(\"syn64892175\", type=\"string\"),\n",
    "    \"mapping_url\": Param(\n",
    "        \"https://raw.githubusercontent.com/amp-als/data-model/refs/heads/main/mapping/cpath.jsonata\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    \"schema_url\": Param(\n",
    "        \"https://raw.githubusercontent.com/amp-als/data-model/refs/heads/main/json-schemas/Dataset.json\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    \"cpath_api_url\": Param(\n",
    "        \"https://fair.dap.c-path.org/api/collections/als-kp/datasets\", type=\"string\"\n",
    "    ),\n",
    "    \"ignore_cpath_datasets\": Param(\"syn68737367\", type=\"string\"),\n",
    "    \"collection_id\": Param(\"syn69962707\", type=\"string\"),\n",
    "    \"synapse_conn_id\": Param(\"SYNAPSE_ORCA_SERVICE_ACCOUNT_CONN\", type=\"string\"),\n",
    "    \n",
    "}\n",
    "\n",
    "dag_config = {\n",
    "    \"schedule_interval\": \"0 0 1 * *\",  # Run on the first day of the month at midnight\n",
    "    \"start_date\": datetime(2025, 5, 1),\n",
    "    \"catchup\": False,\n",
    "    \"default_args\": {\n",
    "        \"retries\": 2,\n",
    "    },\n",
    "    \"tags\": [\"als-kp\"],\n",
    "    \"params\": dag_params,\n",
    "}\n",
    "\n",
    "\n",
    "def load_mapping_from_url(url: str) -> str:\n",
    "    \"\"\"Load the JSONata mapping expression from a URL.\n",
    "\n",
    "    Arguments:\n",
    "        url (str): The URL to fetch the JSONata mapping expression from.\n",
    "\n",
    "    Returns:\n",
    "        str: The JSONata mapping expression as a string.\n",
    "\n",
    "    Raises:\n",
    "        requests.exceptions.RequestException: If the request fails or returns a non-200 status code.\n",
    "        requests.exceptions.Timeout: If the request times out.\n",
    "    \"\"\"\n",
    "    response = requests.get(url, timeout=30)\n",
    "    response.raise_for_status()\n",
    "    return response.text\n",
    "\n",
    "\n",
    "def load_schema_from_url(url: str) -> Dict[str, Any]:\n",
    "    \"\"\"Load the JSON Schema from a URL.\n",
    "\n",
    "    Arguments:\n",
    "        url (str): The URL to fetch the JSON Schema from.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Any]: The parsed JSON Schema as a dictionary.\n",
    "\n",
    "    Raises:\n",
    "        requests.exceptions.RequestException: If the request fails or returns a non-200 status code.\n",
    "        requests.exceptions.Timeout: If the request times out.\n",
    "        json.JSONDecodeError: If the response is not valid JSON.\n",
    "    \"\"\"\n",
    "    response = requests.get(url, timeout=30)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def validate_item(\n",
    "    item: Dict[str, Any], schema: Dict[str, Any]\n",
    ") -> Tuple[bool, Optional[str]]:\n",
    "    \"\"\"Validate an item against a JSON Schema.\n",
    "\n",
    "    Arguments:\n",
    "        item (Dict[str, Any]): The item to validate.\n",
    "        schema (Dict[str, Any]): The JSON Schema to validate against.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[bool, Optional[str]]: A tuple containing:\n",
    "            - bool: True if the item is valid, False otherwise.\n",
    "            - Optional[str]: Error message if validation fails, None if validation succeeds.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        validate(instance=item, schema=schema)\n",
    "        return True, None\n",
    "    except ValidationError as e:\n",
    "        return False, str(e)\n",
    "\n",
    "\n",
    "def transform_with_jsonata(\n",
    "    source_items: List[Dict[str, Any]],\n",
    "    mapping_expr: str,\n",
    "    schema: Optional[Dict[str, Any]] = None,\n",
    ") -> Tuple[List[Dict[str, Any]], List[Dict[str, Any]]]:\n",
    "    \"\"\"Transform a list of items using a JSONata expression and validate against schema.\n",
    "\n",
    "    Arguments:\n",
    "        source_items (List[Dict[str, Any]]): List of source items to transform.\n",
    "        mapping_expr (str): The JSONata mapping expression to apply.\n",
    "        schema (Optional[Dict[str, Any]], optional): JSON Schema to validate transformed items against.\n",
    "            If None, no validation is performed. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[Dict[str, Any]], List[Dict[str, Any]]]: A tuple containing:\n",
    "            - List[Dict[str, Any]]: List of successfully transformed and validated items.\n",
    "            - List[Dict[str, Any]]: List of validation errors, each containing:\n",
    "                - item_index (int): Index of the item that failed validation\n",
    "                - error (str): Validation error message\n",
    "                - transformed_item (Dict[str, Any]): The transformed item that failed validation\n",
    "\n",
    "    Raises:\n",
    "        jsonata.JsonataError: If the JSONata expression is invalid.\n",
    "    \"\"\"\n",
    "    expr = jsonata.Jsonata(mapping_expr)\n",
    "    transformed_items: List[Dict[str, Any]] = []\n",
    "    validation_errors: List[Dict[str, Any]] = []\n",
    "\n",
    "    for i, item in enumerate(source_items):\n",
    "        result = expr.evaluate(item)\n",
    "        if schema:\n",
    "            is_valid, error = validate_item(result, schema)\n",
    "            if not is_valid:\n",
    "                validation_errors.append(\n",
    "                    {\"item_index\": i, \"error\": error, \"transformed_item\": result}\n",
    "                )\n",
    "                continue\n",
    "        transformed_items.append(result)\n",
    "\n",
    "    return transformed_items, validation_errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce9d93c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_cpath_data(**context) -> Dict[str, Any]:\n",
    "        \"\"\"Fetch data from C-Path API using auth token from Airflow Variables.\n",
    "\n",
    "        Arguments:\n",
    "            **context: Airflow task context containing DAG parameters\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, Any]: JSON response from the C-Path API containing dataset items\n",
    "\n",
    "        Raises:\n",
    "            requests.exceptions.RequestException: If the API request fails\n",
    "        \"\"\"\n",
    "        headers = {\n",
    "            \"accept\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {'eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiIsImtpZCI6IjA5YWMyOTY0LTQzZTYtNDQ0ZC05MjhkLTg4ODgyYmQ5NGVjYSJ9.eyJleHAiOjE3NjE4Njg3OTksIm5iZiI6MTc1OTE4ODg0MSwiaWF0IjoxNzU5MTg4ODQxLCJzdWIiOiI2ZDFiYTNjYi02MWY5LTRhNDctYTEyYS0xMDMyMTAzZGYxYjciLCJpc3MiOiJodHRwczovL2ZhaXIuZGFwLmMtcGF0aC5vcmcvYXBpIiwiYXVkIjoiYXJpZGhpYSIsInRva2VuIjoic2FnZS1jcGF0aC1hcGktdG9rZW4ifQ.fSC-ZbL_Q7IGQwSrVR8ydYwQumM3k5f3QEm2LNK1ipM'}\",\n",
    "        }\n",
    "\n",
    "        response = requests.get(context[\"params\"][\"cpath_api_url\"], headers=headers)\n",
    "        response.raise_for_status()\n",
    "        return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c594c71b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'items': [{'id': 1725,\n",
       "   'code': 'fm2_als1001_2024_08_31',\n",
       "   'created_at': '2024-10-29T23:38:49.140Z',\n",
       "   'updated_at': '2025-07-23T21:14:13.791Z',\n",
       "   'catalogue': {'title': 'Clinical Trial Ceftriaxone in Subjects With ALS',\n",
       "    'description': 'The purpose of the study is to evaluate the safety and efficacy of ceftriaxone treatment in amyotrophic lateral sclerosis (ALS).  Ceftriaxone is approved by the U.S. Food and Drug Administration (FDA) for treating bacterial infections but not for treating ALS. Also, ceftriaxone has not been given to people over a long period of time, such as months or years. The goals of this study are to evaluate the safety and effectiveness of ceftriaxone as a treatment for ALS, and to determine the safety and effectiveness of long-term use of the drug in people with ALS.',\n",
       "    'nctId': [{'link': 'https://www.clinicaltrials.gov/study/NCT00349622',\n",
       "      'text': 'NCT00349622'}],\n",
       "    'rights': 'https://portal.rdca.c-path.org/data-use-agreement',\n",
       "    'creator': [{'creatorUrl': 'https://www.massgeneral.org/',\n",
       "      'creatorName': 'Massachusetts General Hospital'}],\n",
       "    'disease': [{'link': 'http://purl.obolibrary.org/obo/MONDO_0004976',\n",
       "      'text': 'amyotrophic lateral sclerosis'}],\n",
       "    'keyword': ['ALS',\n",
       "     'Amyotrophic Lateral Sclerosis',\n",
       "     'disorder',\n",
       "     'neurodegenerative',\n",
       "     'placebo',\n",
       "     'cephalosporin antibiotic',\n",
       "     'motor neurons'],\n",
       "    'language': ['en'],\n",
       "    'publisher': {'link': 'https://c-path.org/',\n",
       "     'text': 'Critical Path Institute'},\n",
       "    'studyType': ['Clinical Trial',\n",
       "     'Natural History Study',\n",
       "     'Patient Registry Study'],\n",
       "    'contactPoint': 'rdcadap@c-path.org',\n",
       "    'curationLevel': 'Non-Standardized',\n",
       "    'accessApprover': ['Contributor', 'No Approver Named'],\n",
       "    'scopeOfDisclosure': ['Approved Users']},\n",
       "   'settings': {'minimum_cohort_size': 50,\n",
       "    'allow_dataset_update_subscriptions': False,\n",
       "    'dataset_actions': [],\n",
       "    'workflow_key': 'rdca_access_request',\n",
       "    'allow_clear': True,\n",
       "    'allow_pseudonymised': False,\n",
       "    'allow_manual': False,\n",
       "    'allow_token': False,\n",
       "    'allow_private_cohorts': False,\n",
       "    'allow_internal_cohorts': False,\n",
       "    'expose_cohort_counts': False,\n",
       "    'expose_cohort_visualisations': False,\n",
       "    'visibility': 'internal',\n",
       "    'catalogue_definition_code': 'rdca-custom-catalogue-v4_1'},\n",
       "   'status': {'request_enabled': {'supported': True, 'reasons': []},\n",
       "    'storage_enabled': {'supported': True, 'reasons': []},\n",
       "    'query_enabled': {'supported': False,\n",
       "     'reasons': ['The dataset is not configured for cohort building']},\n",
       "    'source_exists': {'supported': True, 'reasons': []},\n",
       "    'conditional_access': {'supported': False,\n",
       "     'reasons': ['The dataset has no conditions']},\n",
       "    'managed_data': {'supported': True, 'reasons': []},\n",
       "    'request_workspace': {'supported': True, 'reasons': []}},\n",
       "   'primary_dictionary': 'fm2_als1001_2024_08_31_dsfl',\n",
       "   'permissions': {'can_update': False,\n",
       "    'can_destroy': False,\n",
       "    'can_change_visibility': False,\n",
       "    'can_invite_user': False,\n",
       "    'can_remove_user': False,\n",
       "    'can_manage_perms': False,\n",
       "    'can_approve': False,\n",
       "    'can_attach': False,\n",
       "    'can_upload_data': False,\n",
       "    'can_download_data': False,\n",
       "    'can_read_audit': False,\n",
       "    'can_configure_settings': False,\n",
       "    'can_notify': False,\n",
       "    'can_manage_conditions': False,\n",
       "    'can_manage_collections': False,\n",
       "    'can_manage_datasource': False},\n",
       "   'subscriptions': [],\n",
       "   'collections': [{'code': 'progressive-supranuclear-palsy-collection',\n",
       "     'name': 'Neurodegenerative disease'},\n",
       "    {'code': 'als-kp', 'name': 'ALS Knowledge Portal'}]},\n",
       "  {'id': 1796,\n",
       "   'code': 'fv1_als1001_2025_02_26',\n",
       "   'created_at': '2025-03-18T17:56:11.556Z',\n",
       "   'updated_at': '2025-03-21T21:06:37.850Z',\n",
       "   'catalogue': {'title': 'Clinical Trial Ceftriaxone in Subjects With ALS',\n",
       "    'description': 'The purpose of the study is to evaluate the safety and efficacy of ceftriaxone treatment in amyotrophic lateral sclerosis (ALS).  Ceftriaxone is approved by the U.S. Food and Drug Administration (FDA) for treating bacterial infections but not for treating ALS. Also, ceftriaxone has not been given to people over a long period of time, such as months or years. The goals of this study are to evaluate the safety and effectiveness of ceftriaxone as a treatment for ALS, and to determine the safety and effectiveness of long-term use of the drug in people with ALS.',\n",
       "    'nctId': [{'link': 'https://www.clinicaltrials.gov/study/NCT00349622',\n",
       "      'text': 'NCT00349622'}],\n",
       "    'rights': 'https://portal.rdca.c-path.org/data-use-agreement',\n",
       "    'creator': [{'creatorUrl': 'https://www.massgeneral.org/',\n",
       "      'creatorName': 'Massachusetts General Hospital'}],\n",
       "    'disease': [{'link': 'http://purl.obolibrary.org/obo/MONDO_0004976',\n",
       "      'text': 'amyotrophic lateral sclerosis'}],\n",
       "    'keyword': ['ALS',\n",
       "     'Amyotrophic Lateral Sclerosis',\n",
       "     'disorder',\n",
       "     'neurodegenerative',\n",
       "     'placebo',\n",
       "     'cephalosporin antibiotic',\n",
       "     'motor neurons'],\n",
       "    'language': ['en'],\n",
       "    'publisher': {'link': 'https://c-path.org/',\n",
       "     'text': 'Critical Path Institute'},\n",
       "    'studyType': ['Clinical Trial',\n",
       "     'Natural History Study',\n",
       "     'Patient Registry Study'],\n",
       "    'contactPoint': 'rdcadap@c-path.org',\n",
       "    'curationLevel': 'Standardized',\n",
       "    'accessApprover': ['Contributor', 'No Approver Named'],\n",
       "    'additionalNotes': 'For more information on what variables have been standardized in this dataset version and mapping decisions, refer to the Release Notes attached to this page.',\n",
       "    'commonDataModel': {'link': 'https://ohdsi.github.io/CommonDataModel/cdm54.html',\n",
       "     'text': 'OMOP'},\n",
       "    'scopeOfDisclosure': ['Approved Users']},\n",
       "   'settings': {'minimum_cohort_size': 50,\n",
       "    'allow_dataset_update_subscriptions': False,\n",
       "    'dataset_actions': [],\n",
       "    'workflow_key': 'rdca_access_request',\n",
       "    'allow_clear': True,\n",
       "    'allow_pseudonymised': False,\n",
       "    'allow_manual': False,\n",
       "    'allow_token': False,\n",
       "    'allow_private_cohorts': False,\n",
       "    'allow_internal_cohorts': False,\n",
       "    'expose_cohort_counts': False,\n",
       "    'expose_cohort_visualisations': False,\n",
       "    'visibility': 'internal',\n",
       "    'catalogue_definition_code': 'rdca-custom-catalogue-v4_1'},\n",
       "   'status': {'request_enabled': {'supported': True, 'reasons': []},\n",
       "    'storage_enabled': {'supported': True, 'reasons': []},\n",
       "    'query_enabled': {'supported': False,\n",
       "     'reasons': ['The dataset is not configured for cohort building']},\n",
       "    'source_exists': {'supported': True, 'reasons': []},\n",
       "    'conditional_access': {'supported': False,\n",
       "     'reasons': ['The dataset has no conditions']},\n",
       "    'managed_data': {'supported': True, 'reasons': []},\n",
       "    'request_workspace': {'supported': True, 'reasons': []}},\n",
       "   'primary_dictionary': 'fv1_als1001_2025_02_26_cdm_source',\n",
       "   'permissions': {'can_update': False,\n",
       "    'can_destroy': False,\n",
       "    'can_change_visibility': False,\n",
       "    'can_invite_user': False,\n",
       "    'can_remove_user': False,\n",
       "    'can_manage_perms': False,\n",
       "    'can_approve': False,\n",
       "    'can_attach': False,\n",
       "    'can_upload_data': False,\n",
       "    'can_download_data': False,\n",
       "    'can_read_audit': False,\n",
       "    'can_configure_settings': False,\n",
       "    'can_notify': False,\n",
       "    'can_manage_conditions': False,\n",
       "    'can_manage_collections': False,\n",
       "    'can_manage_datasource': False},\n",
       "   'subscriptions': [],\n",
       "   'collections': [{'code': 'progressive-supranuclear-palsy-collection',\n",
       "     'name': 'Neurodegenerative disease'},\n",
       "    {'code': 'als-kp', 'name': 'ALS Knowledge Portal'}]},\n",
       "  {'id': 1845,\n",
       "   'code': 'fv2_als1002_2025_03_25',\n",
       "   'created_at': '2025-06-13T21:44:46.665Z',\n",
       "   'updated_at': '2025-08-28T20:31:40.911Z',\n",
       "   'catalogue': {'title': 'A Study to Evaluate the Efficacy and Safety of Reldesemtiv in Patients With Amyotrophic Lateral Sclerosis (Phase 3)',\n",
       "    'description': 'COURAGE-ALS is a Phase 3, double-blind, randomized, placebo-controlled trial of reldesemtiv in patients aged 18 to 80 with ALS.\\n\\nThe screening and qualification period for the trial will be no more than 21 days in duration. Approximately 555 eligible ALS patients will be randomized (2:1) to receive the following dose of reldesemtiv or placebo (stratified by riluzole use/non-use and edaravone use/non-use) for the first 24 weeks (double-blind, placebo-controlled period):\\n\\n* 300 mg reldesemtiv twice a day for a 600 mg total daily dose (TDD)\\n\\n* Placebo twice daily\\n\\nAt the end of the 24-week double-blind, placebo-controlled period, patients will transition to the active drug period, where all patients will receive the following dose of reldesemtiv for the next 24 weeks:\\n\\n* 300 mg reldesemtiv twice a day for a 600 mg TDD for patients who were not down titrated during the 24 weeks of blinded dosing\\n\\n* 150 mg reldesemtiv twice a day for a 300 mg TDD for patients who were down titrated during the 24 weeks of blinded dosing\\n\\n**Official Title**\\n\\nA Phase 3, Multi-Center, Double-Blind, Randomized, Placebo-Controlled Trial to Evaluate the Efficacy and Safety of Reldesemtiv in Patients With Amyotrophic Lateral Sclerosis (ALS)',\n",
       "    'rights': 'https://portal.rdca.c-path.org/data-use-agreement',\n",
       "    'creator': [{'creatorUrl': 'https://cytokinetics.com/',\n",
       "      'creatorName': 'Cytokinetics, Inc.'}],\n",
       "    'disease': [{'link': 'http://purl.obolibrary.org/obo/MONDO_0004976',\n",
       "      'text': 'amyotrophic lateral sclerosis'}],\n",
       "    'keyword': ['Amyotrophic Lateral Sclerosis',\n",
       "     'ALS',\n",
       "     'CK-2127107',\n",
       "     'Reldesemtiv',\n",
       "     'COURAGE-ALS'],\n",
       "    'language': ['en'],\n",
       "    'publisher': {'link': 'https://c-path.org/',\n",
       "     'text': 'Critical Path Institute'},\n",
       "    'studyType': ['Clinical Trial'],\n",
       "    'contactPoint': 'rdcadap@c-path.org',\n",
       "    'curationLevel': 'Standardized',\n",
       "    'accessApprover': ['Data Access Committee'],\n",
       "    'commonDataModel': {'link': 'https://www.cdisc.org/standards/foundational/sdtm',\n",
       "     'text': 'SDTM'},\n",
       "    'scopeOfDisclosure': ['Approved Users']},\n",
       "   'settings': {'minimum_cohort_size': 50,\n",
       "    'allow_dataset_update_subscriptions': True,\n",
       "    'dataset_actions': [],\n",
       "    'workflow_key': 'rdca_access_request',\n",
       "    'allow_clear': True,\n",
       "    'allow_pseudonymised': False,\n",
       "    'allow_manual': False,\n",
       "    'allow_token': False,\n",
       "    'allow_private_cohorts': True,\n",
       "    'allow_internal_cohorts': True,\n",
       "    'expose_cohort_counts': True,\n",
       "    'expose_cohort_visualisations': True,\n",
       "    'visibility': 'internal',\n",
       "    'catalogue_definition_code': 'rdca-custom-catalogue-v4_1'},\n",
       "   'status': {'request_enabled': {'supported': True, 'reasons': []},\n",
       "    'storage_enabled': {'supported': True, 'reasons': []},\n",
       "    'query_enabled': {'supported': True, 'reasons': []},\n",
       "    'source_exists': {'supported': True, 'reasons': []},\n",
       "    'conditional_access': {'supported': False,\n",
       "     'reasons': ['The dataset has no conditions']},\n",
       "    'managed_data': {'supported': True, 'reasons': []},\n",
       "    'request_workspace': {'supported': True, 'reasons': []}},\n",
       "   'primary_dictionary': 'fv2_als1002_2025_03_25_ce',\n",
       "   'permissions': {'can_update': False,\n",
       "    'can_destroy': False,\n",
       "    'can_change_visibility': False,\n",
       "    'can_invite_user': False,\n",
       "    'can_remove_user': False,\n",
       "    'can_manage_perms': False,\n",
       "    'can_approve': False,\n",
       "    'can_attach': False,\n",
       "    'can_upload_data': False,\n",
       "    'can_download_data': False,\n",
       "    'can_read_audit': False,\n",
       "    'can_configure_settings': False,\n",
       "    'can_notify': False,\n",
       "    'can_manage_conditions': False,\n",
       "    'can_manage_collections': False,\n",
       "    'can_manage_datasource': False},\n",
       "   'subscriptions': [],\n",
       "   'collections': [{'code': 'progressive-supranuclear-palsy-collection',\n",
       "     'name': 'Neurodegenerative disease'},\n",
       "    {'code': 'als-kp', 'name': 'ALS Knowledge Portal'}]},\n",
       "  {'id': 1884,\n",
       "   'code': 'fv2_als1003_2025_04_28',\n",
       "   'created_at': '2025-08-11T19:53:08.494Z',\n",
       "   'updated_at': '2025-08-28T21:02:37.899Z',\n",
       "   'catalogue': {'title': 'A Study to Evaluate Efficacy, Safety and Tolerability of CK-2127107 in Patients With ALS (FORTITUDE-ALS)',\n",
       "    'description': 'The purpose of this study was to assess the effect of CK-2127107 (hereafter referred to as reldesemtiv) versus placebo on respiratory function and other measures of skeletal muscle function in patients with ALS.\\n\\nThis was a phase 2, double-blind, randomized, placebo-controlled, dose ranging study of reldesemtiv in patients with ALS. Eligible patients were randomized (1:1:1:1) to receive placebo or one of three doses of reldesemtiv (150, 300, or 450 mg twice daily) for 12 weeks. Randomization was stratified by riluzole concomitant use/non-use and edaravone concomitant use/non-use. Concomitant riluzole and edaravone were allowed as long as the riluzole dose had been stable for at least 30 days prior to screening and edaravone had been taken for 2 cycles prior to screening; these drugs could not be initiated during the study.\\n\\nA total of 7 study visits were planned: screening, Day 1 (first dosing day), Weeks 2, 4, 8, and 12, and follow-up (4 weeks after the last dose of study drug). Study drug (placebo or reldesemtiv) was to be taken twice daily, approximately 12 hours (± 2 hours) apart and within 2 hours following a meal.',\n",
       "    'rights': 'https://portal.rdca.c-path.org/data-use-agreement',\n",
       "    'creator': [{'creatorUrl': 'https://cytokinetics.com/',\n",
       "      'creatorName': 'Cytokinetics, Inc.'}],\n",
       "    'disease': [{'link': 'http://purl.obolibrary.org/obo/MONDO_0004976',\n",
       "      'text': 'amyotrophic lateral sclerosis'}],\n",
       "    'keyword': ['Amyotrophic Lateral Sclerosis',\n",
       "     'Reldesemtiv',\n",
       "     'Placebo',\n",
       "     'Phase 2',\n",
       "     'respiratory',\n",
       "     'muscle function',\n",
       "     'ALSFRS-R',\n",
       "     'dynamometer',\n",
       "     'CK-2127107'],\n",
       "    'language': ['en'],\n",
       "    'temporal': {'end': 2019, 'start': 2017},\n",
       "    'publisher': {'link': 'https://c-path.org/',\n",
       "     'text': 'Critical Path Institute'},\n",
       "    'studyType': ['Clinical Trial'],\n",
       "    'contactPoint': 'rdcadap@c-path.org',\n",
       "    'curationLevel': 'Standardized',\n",
       "    'accessApprover': ['Data Access Committee'],\n",
       "    'commonDataModel': {'link': 'https://www.cdisc.org/standards/foundational/sdtm',\n",
       "     'text': 'SDTM'},\n",
       "    'scopeOfDisclosure': ['Approved Users']},\n",
       "   'settings': {'minimum_cohort_size': 50,\n",
       "    'allow_dataset_update_subscriptions': False,\n",
       "    'dataset_actions': [],\n",
       "    'workflow_key': 'rdca_access_request',\n",
       "    'allow_clear': True,\n",
       "    'allow_pseudonymised': False,\n",
       "    'allow_manual': False,\n",
       "    'allow_token': False,\n",
       "    'allow_private_cohorts': True,\n",
       "    'allow_internal_cohorts': True,\n",
       "    'expose_cohort_counts': True,\n",
       "    'expose_cohort_visualisations': True,\n",
       "    'visibility': 'internal',\n",
       "    'catalogue_definition_code': 'rdca-custom-catalogue-v4_1'},\n",
       "   'status': {'request_enabled': {'supported': True, 'reasons': []},\n",
       "    'storage_enabled': {'supported': True, 'reasons': []},\n",
       "    'query_enabled': {'supported': True, 'reasons': []},\n",
       "    'source_exists': {'supported': True, 'reasons': []},\n",
       "    'conditional_access': {'supported': False,\n",
       "     'reasons': ['The dataset has no conditions']},\n",
       "    'managed_data': {'supported': True, 'reasons': []},\n",
       "    'request_workspace': {'supported': True, 'reasons': []}},\n",
       "   'primary_dictionary': 'fv2_als1003_2025_04_28_ce',\n",
       "   'permissions': {'can_update': False,\n",
       "    'can_destroy': False,\n",
       "    'can_change_visibility': False,\n",
       "    'can_invite_user': False,\n",
       "    'can_remove_user': False,\n",
       "    'can_manage_perms': False,\n",
       "    'can_approve': False,\n",
       "    'can_attach': False,\n",
       "    'can_upload_data': False,\n",
       "    'can_download_data': False,\n",
       "    'can_read_audit': False,\n",
       "    'can_configure_settings': False,\n",
       "    'can_notify': False,\n",
       "    'can_manage_conditions': False,\n",
       "    'can_manage_collections': False,\n",
       "    'can_manage_datasource': False},\n",
       "   'subscriptions': [],\n",
       "   'collections': [{'code': 'progressive-supranuclear-palsy-collection',\n",
       "     'name': 'Neurodegenerative disease'},\n",
       "    {'code': 'als-kp', 'name': 'ALS Knowledge Portal'}]}],\n",
       " 'paging': {'total': 4, 'page': 1, 'pages': 1},\n",
       " 'additional': {'collection': {'code': 'als-kp',\n",
       "   'name': 'ALS Knowledge Portal',\n",
       "   'permissions': {'can_update': False,\n",
       "    'can_destroy': False,\n",
       "    'can_invite_user': False,\n",
       "    'can_remove_user': False,\n",
       "    'can_manage_perms': False,\n",
       "    'can_read_audit': False,\n",
       "    'can_manage_datasets': False}}}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mock the context that Airflow would provide\n",
    "context = {\n",
    "    \"params\": {\n",
    "        \"cpath_api_url\": \"https://fair.dap.c-path.org/api/collections/als-kp/datasets\",\n",
    "        \"mapping_url\": \"https://raw.githubusercontent.com/amp-als/data-model/refs/heads/main/mapping/cpath.jsonata\",\n",
    "        \"schema_url\":\"https://raw.githubusercontent.com/amp-als/data-model/refs/heads/main/json-schemas/Dataset.json\",\n",
    "        \"ignore_cpath_datasets\": \"syn68737367\",\n",
    "        \"collection_id\": \"syn69962707\",\n",
    "        \"synapse_conn_id\": \"SYNAPSE_ORCA_SERVICE_ACCOUNT_CONN\",\n",
    "        \"project_id\": \"syn64892175\"\n",
    "    }\n",
    "}\n",
    "\n",
    "data = fetch_cpath_data(**context)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b9c7a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(data: Dict[str, Any], **context) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Transform the data using JSONata mapping and validate against schema.\n",
    "\n",
    "        This task:\n",
    "        1. Loads the JSONata mapping expression from the specified URL\n",
    "        2. Loads the JSON Schema from the specified URL\n",
    "        3. Applies the mapping to each item in the input data\n",
    "        4. Validates each transformed item against the schema\n",
    "        5. Returns only the valid transformed items\n",
    "\n",
    "        Arguments:\n",
    "            data: Raw data from the C-Path API\n",
    "            **context: Airflow task context containing DAG parameters\n",
    "\n",
    "        Returns:\n",
    "            List[Dict[str, Any]]: List of transformed and validated items\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If any validation errors are found\n",
    "            requests.exceptions.RequestException: If loading mapping or schema fails\n",
    "        \"\"\"\n",
    "        mapping_expr = load_mapping_from_url(context[\"params\"][\"mapping_url\"])\n",
    "\n",
    "        schema = load_schema_from_url(context[\"params\"][\"schema_url\"])\n",
    "        #print(schema)\n",
    "        #print(mapping_expr)\n",
    "        transformed_items, validation_errors = transform_with_jsonata(\n",
    "            data[\"items\"], mapping_expr, schema\n",
    "        )\n",
    "        if validation_errors:\n",
    "            print(validation_errors)\n",
    "            raise ValueError(f\"Found {len(validation_errors)} validation errors.\")\n",
    "            \n",
    "\n",
    "        return transformed_items, validation_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49e1b1c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Clinical Trial Ceftriaxone in Subjects With ALS',\n",
       "  'creator': ['Massachusetts General Hospital'],\n",
       "  'keywords': ['ALS',\n",
       "   'Amyotrophic Lateral Sclerosis',\n",
       "   'disorder',\n",
       "   'neurodegenerative',\n",
       "   'placebo',\n",
       "   'cephalosporin antibiotic',\n",
       "   'motor neurons'],\n",
       "  'subject': ['amyotrophic lateral sclerosis'],\n",
       "  'description': 'The purpose of the study is to evaluate the safety and efficacy of ceftriaxone treatment in amyotrophic lateral sclerosis (ALS).  Ceftriaxone is approved by the U.S. Food and Drug Administration (FDA) for treating bacterial infections but not for treating ALS. Also, ceftriaxone has not been given to people over a long period of time, such as months or years. The goals of this study are to evaluate the safety and effectiveness of ceftriaxone as a treatment for ALS, and to determine the safety and effectiveness of long-term use of the drug in people with ALS.',\n",
       "  'collection': ['ALS Knowledge Portal'],\n",
       "  'publisher': 'Critical Path Institute',\n",
       "  'species': ['Homo sapiens'],\n",
       "  'sameAs': 'cpath:1725',\n",
       "  'curationLevel': 'Non-Standardized',\n",
       "  'studyType': ['Clinical Trial',\n",
       "   'Natural History Study',\n",
       "   'Patient Registry Study'],\n",
       "  'source': 'Critical Path Institute',\n",
       "  'url': 'https://fair.dap.c-path.org/#/data/datasets/fm2_als1001_2024_08_31',\n",
       "  'contributor': ['Massachusetts General Hospital']},\n",
       " {'title': 'Clinical Trial Ceftriaxone in Subjects With ALS',\n",
       "  'creator': ['Massachusetts General Hospital'],\n",
       "  'keywords': ['ALS',\n",
       "   'Amyotrophic Lateral Sclerosis',\n",
       "   'disorder',\n",
       "   'neurodegenerative',\n",
       "   'placebo',\n",
       "   'cephalosporin antibiotic',\n",
       "   'motor neurons'],\n",
       "  'subject': ['amyotrophic lateral sclerosis'],\n",
       "  'description': 'The purpose of the study is to evaluate the safety and efficacy of ceftriaxone treatment in amyotrophic lateral sclerosis (ALS).  Ceftriaxone is approved by the U.S. Food and Drug Administration (FDA) for treating bacterial infections but not for treating ALS. Also, ceftriaxone has not been given to people over a long period of time, such as months or years. The goals of this study are to evaluate the safety and effectiveness of ceftriaxone as a treatment for ALS, and to determine the safety and effectiveness of long-term use of the drug in people with ALS.',\n",
       "  'collection': ['ALS Knowledge Portal'],\n",
       "  'publisher': 'Critical Path Institute',\n",
       "  'species': ['Homo sapiens'],\n",
       "  'sameAs': 'cpath:1796',\n",
       "  'curationLevel': 'Standardized',\n",
       "  'studyType': ['Clinical Trial',\n",
       "   'Natural History Study',\n",
       "   'Patient Registry Study'],\n",
       "  'source': 'Critical Path Institute',\n",
       "  'url': 'https://fair.dap.c-path.org/#/data/datasets/fv1_als1001_2025_02_26',\n",
       "  'contributor': ['Massachusetts General Hospital']},\n",
       " {'title': 'A Study to Evaluate the Efficacy and Safety of Reldesemtiv in Patients With Amyotrophic Lateral Sclerosis (Phase 3)',\n",
       "  'creator': ['Cytokinetics, Inc.'],\n",
       "  'keywords': ['Amyotrophic Lateral Sclerosis',\n",
       "   'ALS',\n",
       "   'CK-2127107',\n",
       "   'Reldesemtiv',\n",
       "   'COURAGE-ALS'],\n",
       "  'subject': ['amyotrophic lateral sclerosis'],\n",
       "  'description': 'COURAGE-ALS is a Phase 3, double-blind, randomized, placebo-controlled trial of reldesemtiv in patients aged 18 to 80 with ALS.\\n\\nThe screening and qualification period for the trial will be no more than 21 days in duration. Approximately 555 eligible ALS patients will be randomized (2:1) to receive the following dose of reldesemtiv or placebo (stratified by riluzole use/non-use and edaravone use/non-use) for the first 24 weeks (double-blind, placebo-controlled period):\\n\\n* 300 mg reldesemtiv twice a day for a 600 mg total daily dose (TDD)\\n\\n* Placebo twice daily\\n\\nAt the end of the 24-week double-blind, placebo-controlled period, patients will transition to the active drug period, where all patients will receive the following dose of reldesemtiv for the next 24 weeks:\\n\\n* 300 mg reldesemtiv twice a day for a 600 mg TDD for patients who were not down titrated during the 24 weeks of blinded dosing\\n\\n* 150 mg reldesemtiv twice a day for a 300 mg TDD for patients who were down titrated during the 24 weeks of blinded dosing\\n\\n**Official Title**\\n\\nA Phase 3, Multi-Center, Double-Blind, Randomized, Placebo-Controlled Trial to Evaluate the Efficacy and Safety of Reldesemtiv in Patients With Amyotrophic Lateral Sclerosis (ALS)',\n",
       "  'collection': ['ALS Knowledge Portal'],\n",
       "  'publisher': 'Critical Path Institute',\n",
       "  'species': ['Homo sapiens'],\n",
       "  'sameAs': 'cpath:1845',\n",
       "  'curationLevel': 'Standardized',\n",
       "  'studyType': ['Clinical Trial'],\n",
       "  'source': 'Critical Path Institute',\n",
       "  'url': 'https://fair.dap.c-path.org/#/data/datasets/fv2_als1002_2025_03_25',\n",
       "  'contributor': ['Cytokinetics, Inc.']},\n",
       " {'title': 'A Study to Evaluate Efficacy, Safety and Tolerability of CK-2127107 in Patients With ALS (FORTITUDE-ALS)',\n",
       "  'creator': ['Cytokinetics, Inc.'],\n",
       "  'keywords': ['Amyotrophic Lateral Sclerosis',\n",
       "   'Reldesemtiv',\n",
       "   'Placebo',\n",
       "   'Phase 2',\n",
       "   'respiratory',\n",
       "   'muscle function',\n",
       "   'ALSFRS-R',\n",
       "   'dynamometer',\n",
       "   'CK-2127107'],\n",
       "  'subject': ['amyotrophic lateral sclerosis'],\n",
       "  'description': 'The purpose of this study was to assess the effect of CK-2127107 (hereafter referred to as reldesemtiv) versus placebo on respiratory function and other measures of skeletal muscle function in patients with ALS.\\n\\nThis was a phase 2, double-blind, randomized, placebo-controlled, dose ranging study of reldesemtiv in patients with ALS. Eligible patients were randomized (1:1:1:1) to receive placebo or one of three doses of reldesemtiv (150, 300, or 450 mg twice daily) for 12 weeks. Randomization was stratified by riluzole concomitant use/non-use and edaravone concomitant use/non-use. Concomitant riluzole and edaravone were allowed as long as the riluzole dose had been stable for at least 30 days prior to screening and edaravone had been taken for 2 cycles prior to screening; these drugs could not be initiated during the study.\\n\\nA total of 7 study visits were planned: screening, Day 1 (first dosing day), Weeks 2, 4, 8, and 12, and follow-up (4 weeks after the last dose of study drug). Study drug (placebo or reldesemtiv) was to be taken twice daily, approximately 12 hours (± 2 hours) apart and within 2 hours following a meal.',\n",
       "  'collection': ['ALS Knowledge Portal'],\n",
       "  'publisher': 'Critical Path Institute',\n",
       "  'species': ['Homo sapiens'],\n",
       "  'sameAs': 'cpath:1884',\n",
       "  'curationLevel': 'Standardized',\n",
       "  'studyType': ['Clinical Trial'],\n",
       "  'source': 'Critical Path Institute',\n",
       "  'url': 'https://fair.dap.c-path.org/#/data/datasets/fv2_als1003_2025_04_28',\n",
       "  'contributor': ['Cytokinetics, Inc.']}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_items, validation_errors = transform_data(data, **context)\n",
    "transformed_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26fb7ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dataset_code(dataset_code: str) -> Tuple[str, str, str]:\n",
    "    \"\"\"Parse dataset code to extract ALS number, prefix, and date.\n",
    "\n",
    "    Args:\n",
    "        dataset_code: e.g., \"src_als1003_2025_04_17\", \"fv1_als1001_2025_02_26\"\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (als_number, prefix, date_str)\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If dataset code format is invalid\n",
    "    \"\"\"\n",
    "    import re\n",
    "\n",
    "    # Pattern to match: prefix_als{number}_{date}\n",
    "    pattern = r'^(src_|fm[12]_|fv[123]_)(als\\d+)_(\\d{4}_\\d{2}_\\d{2})$'\n",
    "    match = re.match(pattern, dataset_code)\n",
    "\n",
    "    if not match:\n",
    "        raise ValueError(f\"Invalid dataset code format: {dataset_code}\")\n",
    "\n",
    "    prefix = match.group(1).rstrip('_')  # Remove trailing underscore\n",
    "    als_number = match.group(2)\n",
    "    date_str = match.group(3)\n",
    "\n",
    "    return als_number, prefix, date_str\n",
    "\n",
    "\n",
    "def extract_dataset_code_from_url(url: str) -> str:\n",
    "    \"\"\"Extract dataset code from C-Path URL.\n",
    "\n",
    "    Args:\n",
    "        url: e.g., \"https://fair.dap.c-path.org/#/data/datasets/src_als1003_2025_04_17\"\n",
    "\n",
    "    Returns:\n",
    "        Dataset code e.g., \"src_als1003_2025_04_17\"\n",
    "    \"\"\"\n",
    "    if not url:\n",
    "        return \"\"\n",
    "    return url.split(\"/\")[-1]\n",
    "\n",
    "\n",
    "def get_version_priority(prefix: str) -> int:\n",
    "    \"\"\"Get priority score for dataset prefix (higher = better).\n",
    "\n",
    "    Priority: fv3 > fv2 > fv1 > fm2 > fm1 > src\n",
    "    \"\"\"\n",
    "    priority_map = {\n",
    "        'fv3': 6,\n",
    "        'fv2': 5,\n",
    "        'fv1': 4,\n",
    "        'fm2': 3,\n",
    "        'fm1': 2,\n",
    "        'src': 1\n",
    "    }\n",
    "    return priority_map.get(prefix, 0)\n",
    "\n",
    "\n",
    "def select_latest_versions(datasets: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Select the latest and greatest version for each ALS dataset group.\n",
    "\n",
    "    Args:\n",
    "        datasets: List of dataset items with 'url' field containing dataset codes\n",
    "\n",
    "    Returns:\n",
    "        List of selected datasets (one per ALS number)\n",
    "    \"\"\"\n",
    "    from collections import defaultdict\n",
    "    from datetime import datetime\n",
    "\n",
    "    # Group datasets by ALS number\n",
    "    als_groups = defaultdict(list)\n",
    "\n",
    "    for dataset in datasets:\n",
    "        url = dataset.get(\"url\", \"\")\n",
    "        dataset_code = extract_dataset_code_from_url(url)\n",
    "\n",
    "        if not dataset_code:\n",
    "            print(f\"Skipping dataset with missing URL: {dataset.get('title', 'Unknown')}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            als_number, prefix, date_str = parse_dataset_code(dataset_code)\n",
    "            als_groups[als_number].append({\n",
    "                'dataset': dataset,\n",
    "                'prefix': prefix,\n",
    "                'date_str': date_str,\n",
    "                'priority': get_version_priority(prefix),\n",
    "                'dataset_code': dataset_code\n",
    "            })\n",
    "        except ValueError as e:\n",
    "            print(f\"Skipping dataset with invalid code: {dataset_code}, error: {e}\")\n",
    "            continue\n",
    "\n",
    "    selected_datasets = []\n",
    "\n",
    "    # For each ALS group, select the best version\n",
    "    for als_number, versions in als_groups.items():\n",
    "        # Sort by priority (desc), then by date (desc)\n",
    "        best_version = max(versions, key=lambda x: (\n",
    "            x['priority'],\n",
    "            datetime.strptime(x['date_str'], '%Y_%m_%d')\n",
    "        ))\n",
    "\n",
    "        selected_datasets.append(best_version['dataset'])\n",
    "        print(f\"Selected {best_version['dataset_code']} for {als_number} \"\n",
    "              f\"(priority: {best_version['priority']}, date: {best_version['date_str']})\")\n",
    "\n",
    "    return selected_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0e546cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_duplicated_datasets(\n",
    "    transformed_items: List[Dict[str, Any]], **context\n",
    ") -> Tuple[List[Dict[str, Any]], List[Dict[str, Any]]]:\n",
    "    \"\"\"Apply latest and greatest version selection for ALS datasets.\n",
    "\n",
    "    This task:\n",
    "    1. Retrieves the current C-PATH datasets from Synapse.\n",
    "    2. Filters out datasets that already exist in the collection.\n",
    "    3. Groups remaining datasets by ALS number and selects the latest version.\n",
    "\n",
    "    Arguments:\n",
    "        transformed_items (List[Dict[str, Any]]):\n",
    "            A list of transformed and validated items from the previous task.\n",
    "        **context: Airflow task context containing DAG parameters\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[Dict[str, Any]], List[Dict[str, Any]]]:\n",
    "            - Selected datasets to ingest\n",
    "            - Empty list (no duplicates for manual review)\n",
    "    \"\"\"\n",
    "    syn_hook = SynapseHook(context[\"params\"][\"synapse_conn_id\"])\n",
    "    synapse_client = syn_hook.client\n",
    "\n",
    "    # Get current datasets (using sameAs field which has cpath:ID format)\n",
    "    collection_id = context[\"params\"][\"collection_id\"]\n",
    "    query_str = (\n",
    "        f\"SELECT * FROM {collection_id} WHERE source='Critical Path Institute'\"\n",
    "    )\n",
    "\n",
    "    current_data = synapse_client.tableQuery(query_str).asDataFrame()\n",
    "    current_datasets = set(current_data[\"sameAs\"].tolist())\n",
    "\n",
    "    # Filter out items that already exist (check by sameAs field)\n",
    "    new_items = []\n",
    "    for item in transformed_items:\n",
    "        cpath_key = item.get(\"sameAs\")  # This is \"cpath:1725\" format\n",
    "        title = item.get(\"title\")\n",
    "        url = item.get(\"url\")\n",
    "\n",
    "        if not cpath_key:\n",
    "            raise ValueError(f\"Missing or empty 'sameAs' in item: {item}\")\n",
    "        if not title:\n",
    "            raise ValueError(f\"Missing or empty 'title' in item: {item}\")\n",
    "        if not url:\n",
    "            raise ValueError(f\"Missing or empty 'url' in item: {item}\")\n",
    "\n",
    "        if cpath_key not in current_datasets:\n",
    "            new_items.append(item)\n",
    "\n",
    "    print(f\"Found {len(new_items)} new items to process from {len(transformed_items)} total items\")\n",
    "\n",
    "    # Apply latest and greatest selection using URL field for ALS codes\n",
    "    selected_items = select_latest_versions(new_items)\n",
    "\n",
    "    print(f\"Selected {len(selected_items)} datasets from {len(new_items)} new items\")\n",
    "\n",
    "    # Return selected items and empty duplicates list (no manual review needed)\n",
    "    return selected_items, []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d55b4437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2025-10-08T23:30:35.602+0000\u001b[0m] {\u001b[34mcrypto.py:\u001b[0m82} \u001b[33mWARNING\u001b[0m - \u001b[33mempty cryptography key - values will not be stored encrypted.\u001b[0m\n",
      "[\u001b[34m2025-10-08T23:30:35.603+0000\u001b[0m] {\u001b[34mbase.py:\u001b[0m84} INFO\u001b[0m - Retrieving connection 'SYNAPSE_ORCA_SERVICE_ACCOUNT_CONN'\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Querying table/view: 'syn69962707' ...:   0%|          | 0.00/100 [00:01<?, ?it/s]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2025-10-08T23:30:38.207+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: POST https://file-prod.prod.sagebase.org/file/v1/fileHandle/batch \"HTTP/1.1 201 \"\u001b[0m\n",
      "Found 2 new items to process from 4 total items\n",
      "Selected fm2_als1001_2024_08_31 for als1001 (priority: 3, date: 2024_08_31)\n",
      "Selected fv2_als1003_2025_04_28 for als1003 (priority: 5, date: 2025_04_28)\n",
      "Selected 2 datasets from 2 new items\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'title': 'Clinical Trial Ceftriaxone in Subjects With ALS',\n",
       "  'creator': ['Massachusetts General Hospital'],\n",
       "  'keywords': ['ALS',\n",
       "   'Amyotrophic Lateral Sclerosis',\n",
       "   'disorder',\n",
       "   'neurodegenerative',\n",
       "   'placebo',\n",
       "   'cephalosporin antibiotic',\n",
       "   'motor neurons'],\n",
       "  'subject': ['amyotrophic lateral sclerosis'],\n",
       "  'description': 'The purpose of the study is to evaluate the safety and efficacy of ceftriaxone treatment in amyotrophic lateral sclerosis (ALS).  Ceftriaxone is approved by the U.S. Food and Drug Administration (FDA) for treating bacterial infections but not for treating ALS. Also, ceftriaxone has not been given to people over a long period of time, such as months or years. The goals of this study are to evaluate the safety and effectiveness of ceftriaxone as a treatment for ALS, and to determine the safety and effectiveness of long-term use of the drug in people with ALS.',\n",
       "  'collection': ['ALS Knowledge Portal'],\n",
       "  'publisher': 'Critical Path Institute',\n",
       "  'species': ['Homo sapiens'],\n",
       "  'sameAs': 'cpath:1725',\n",
       "  'curationLevel': 'Non-Standardized',\n",
       "  'studyType': ['Clinical Trial',\n",
       "   'Natural History Study',\n",
       "   'Patient Registry Study'],\n",
       "  'source': 'Critical Path Institute',\n",
       "  'url': 'https://fair.dap.c-path.org/#/data/datasets/fm2_als1001_2024_08_31',\n",
       "  'contributor': ['Massachusetts General Hospital']},\n",
       " {'title': 'A Study to Evaluate Efficacy, Safety and Tolerability of CK-2127107 in Patients With ALS (FORTITUDE-ALS)',\n",
       "  'creator': ['Cytokinetics, Inc.'],\n",
       "  'keywords': ['Amyotrophic Lateral Sclerosis',\n",
       "   'Reldesemtiv',\n",
       "   'Placebo',\n",
       "   'Phase 2',\n",
       "   'respiratory',\n",
       "   'muscle function',\n",
       "   'ALSFRS-R',\n",
       "   'dynamometer',\n",
       "   'CK-2127107'],\n",
       "  'subject': ['amyotrophic lateral sclerosis'],\n",
       "  'description': 'The purpose of this study was to assess the effect of CK-2127107 (hereafter referred to as reldesemtiv) versus placebo on respiratory function and other measures of skeletal muscle function in patients with ALS.\\n\\nThis was a phase 2, double-blind, randomized, placebo-controlled, dose ranging study of reldesemtiv in patients with ALS. Eligible patients were randomized (1:1:1:1) to receive placebo or one of three doses of reldesemtiv (150, 300, or 450 mg twice daily) for 12 weeks. Randomization was stratified by riluzole concomitant use/non-use and edaravone concomitant use/non-use. Concomitant riluzole and edaravone were allowed as long as the riluzole dose had been stable for at least 30 days prior to screening and edaravone had been taken for 2 cycles prior to screening; these drugs could not be initiated during the study.\\n\\nA total of 7 study visits were planned: screening, Day 1 (first dosing day), Weeks 2, 4, 8, and 12, and follow-up (4 weeks after the last dose of study drug). Study drug (placebo or reldesemtiv) was to be taken twice daily, approximately 12 hours (± 2 hours) apart and within 2 hours following a meal.',\n",
       "  'collection': ['ALS Knowledge Portal'],\n",
       "  'publisher': 'Critical Path Institute',\n",
       "  'species': ['Homo sapiens'],\n",
       "  'sameAs': 'cpath:1884',\n",
       "  'curationLevel': 'Standardized',\n",
       "  'studyType': ['Clinical Trial'],\n",
       "  'source': 'Critical Path Institute',\n",
       "  'url': 'https://fair.dap.c-path.org/#/data/datasets/fv2_als1003_2025_04_28',\n",
       "  'contributor': ['Cytokinetics, Inc.']}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_items, duplicates = find_duplicated_datasets(transformed_items, **context)\n",
    "selected_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e58080ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_existing_als_datasets(syn_hook, collection_id: str) -> Dict[str, Dict[str, Any]]:\n",
    "    \"\"\"Get all existing ALS datasets from the collection, grouped by ALS number.\n",
    "\n",
    "    Returns:\n",
    "        Dict mapping als_number -> dataset_info with fields:\n",
    "        - synapse_id, dataset_code, prefix, priority, date_str, sameAs\n",
    "    \"\"\"\n",
    "    synapse_client = syn_hook.client\n",
    "    query_str = f\"SELECT * FROM {collection_id} WHERE publisher='Critical Path Institute'\"\n",
    "    current_data = synapse_client.tableQuery(query_str).asDataFrame()\n",
    "\n",
    "    existing_datasets = {}\n",
    "\n",
    "    for _, row in current_data.iterrows():\n",
    "        url = row.get('url', '')\n",
    "        dataset_code = extract_dataset_code_from_url(url)\n",
    "\n",
    "        if not dataset_code:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            als_number, prefix, date_str = parse_dataset_code(dataset_code)\n",
    "            existing_datasets[als_number] = {\n",
    "                'synapse_id': row['id'],\n",
    "                'dataset_code': dataset_code,\n",
    "                'prefix': prefix,\n",
    "                'priority': get_version_priority(prefix),\n",
    "                'date_str': date_str,\n",
    "                'sameAs': row['sameAs'],\n",
    "                'url': row['url']\n",
    "            }\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "    return existing_datasets\n",
    "\n",
    "\n",
    "def identify_dataset_actions(\n",
    "    selected_items: List[Dict[str, Any]], **context\n",
    ") -> Tuple[List[Dict[str, Any]], List[Dict[str, Any]]]:\n",
    "    \"\"\"Identify which datasets need new versions vs new creation.\"\"\"\n",
    "\n",
    "    syn_hook = SynapseHook(context[\"params\"][\"synapse_conn_id\"])\n",
    "    collection_id = context[\"params\"][\"collection_id\"]\n",
    "\n",
    "    # Get existing datasets\n",
    "    existing_datasets = get_existing_als_datasets(syn_hook, collection_id)\n",
    "\n",
    "    datasets_to_create = []\n",
    "    datasets_to_update = []\n",
    "\n",
    "    for item in selected_items:\n",
    "        url = item.get(\"url\", \"\")\n",
    "        dataset_code = extract_dataset_code_from_url(url)\n",
    "\n",
    "        if not dataset_code:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            als_number, new_prefix, new_date_str = parse_dataset_code(dataset_code)\n",
    "            new_priority = get_version_priority(new_prefix)\n",
    "            new_date = datetime.strptime(new_date_str, '%Y_%m_%d')\n",
    "\n",
    "            if als_number in existing_datasets:\n",
    "                existing = existing_datasets[als_number]\n",
    "                existing_date = datetime.strptime(existing['date_str'], '%Y_%m_%d')\n",
    "\n",
    "                # Check if we should update (version upgrade OR same version with potential annotation changes)\n",
    "                should_update = (\n",
    "                    new_priority > existing['priority'] or\n",
    "                    (new_priority == existing['priority'] and new_date >= existing_date)\n",
    "                )\n",
    "\n",
    "                if should_update:\n",
    "                    upgrade_type = 'version' if new_priority > existing['priority'] else 'annotation'\n",
    "                    datasets_to_update.append({\n",
    "                        'new_data': item,\n",
    "                        'existing_synapse_id': existing['synapse_id'],\n",
    "                        'upgrade_type': upgrade_type,\n",
    "                        'dataset_code': dataset_code\n",
    "                    })\n",
    "                    print(f\"Will update {existing['dataset_code']} -> {dataset_code} ({upgrade_type})\")\n",
    "                else:\n",
    "                    print(f\"Skipping {dataset_code} (no improvement over {existing['dataset_code']})\")\n",
    "            else:\n",
    "                # Completely new ALS number\n",
    "                datasets_to_create.append(item)\n",
    "                print(f\"Will create new dataset: {dataset_code}\")\n",
    "\n",
    "        except ValueError as e:\n",
    "            print(f\"Skipping invalid dataset code {dataset_code}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return datasets_to_create, datasets_to_update\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8c09679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2025-10-08T23:31:17.145+0000\u001b[0m] {\u001b[34mbase.py:\u001b[0m84} INFO\u001b[0m - Retrieving connection 'SYNAPSE_ORCA_SERVICE_ACCOUNT_CONN'\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Querying table/view: 'syn69962707' ...:   0%|          | 0.00/100 [00:00<?, ?it/s]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2025-10-08T23:31:18.484+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: POST https://file-prod.prod.sagebase.org/file/v1/fileHandle/batch \"HTTP/1.1 201 \"\u001b[0m\n",
      "Skipping fm2_als1001_2024_08_31 (no improvement over fv1_als1001_2025_02_26)\n",
      "Will create new dataset: fv2_als1003_2025_04_28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'title': 'A Study to Evaluate Efficacy, Safety and Tolerability of CK-2127107 in Patients With ALS (FORTITUDE-ALS)',\n",
       "  'creator': ['Cytokinetics, Inc.'],\n",
       "  'keywords': ['Amyotrophic Lateral Sclerosis',\n",
       "   'Reldesemtiv',\n",
       "   'Placebo',\n",
       "   'Phase 2',\n",
       "   'respiratory',\n",
       "   'muscle function',\n",
       "   'ALSFRS-R',\n",
       "   'dynamometer',\n",
       "   'CK-2127107'],\n",
       "  'subject': ['amyotrophic lateral sclerosis'],\n",
       "  'description': 'The purpose of this study was to assess the effect of CK-2127107 (hereafter referred to as reldesemtiv) versus placebo on respiratory function and other measures of skeletal muscle function in patients with ALS.\\n\\nThis was a phase 2, double-blind, randomized, placebo-controlled, dose ranging study of reldesemtiv in patients with ALS. Eligible patients were randomized (1:1:1:1) to receive placebo or one of three doses of reldesemtiv (150, 300, or 450 mg twice daily) for 12 weeks. Randomization was stratified by riluzole concomitant use/non-use and edaravone concomitant use/non-use. Concomitant riluzole and edaravone were allowed as long as the riluzole dose had been stable for at least 30 days prior to screening and edaravone had been taken for 2 cycles prior to screening; these drugs could not be initiated during the study.\\n\\nA total of 7 study visits were planned: screening, Day 1 (first dosing day), Weeks 2, 4, 8, and 12, and follow-up (4 weeks after the last dose of study drug). Study drug (placebo or reldesemtiv) was to be taken twice daily, approximately 12 hours (± 2 hours) apart and within 2 hours following a meal.',\n",
       "  'collection': ['ALS Knowledge Portal'],\n",
       "  'publisher': 'Critical Path Institute',\n",
       "  'species': ['Homo sapiens'],\n",
       "  'sameAs': 'cpath:1884',\n",
       "  'curationLevel': 'Standardized',\n",
       "  'studyType': ['Clinical Trial'],\n",
       "  'source': 'Critical Path Institute',\n",
       "  'url': 'https://fair.dap.c-path.org/#/data/datasets/fv2_als1003_2025_04_28',\n",
       "  'contributor': ['Cytokinetics, Inc.']}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_to_create, datasets_to_update = identify_dataset_actions(selected_items,**context)\n",
    "datasets_to_create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e0cc79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ignored_datasets(**context) -> List[str]:\n",
    "    \"\"\"Datasets that need to be ignored after human review and validation\n",
    "\n",
    "    This task:\n",
    "    1. Retrieve json file: ignore_cpath_datasets.json\n",
    "    2. Read the file and get a list of C-path datasets that need to be ignored based on the C-Path identifier.\n",
    "\n",
    "    Arguments:\n",
    "        **context: Airflow task context containing DAG parameters\n",
    "    Returns:\n",
    "        List[str]: A list of C-Path identifiers to be ignored\n",
    "    \"\"\"\n",
    "    syn_hook = SynapseHook(context[\"params\"][\"synapse_conn_id\"])\n",
    "    synapse_client = syn_hook.client\n",
    "\n",
    "    # Find datasets that need to be ignored\n",
    "    ignore_cpath_datasets_json = context[\"params\"][\"ignore_cpath_datasets\"]\n",
    "    file = File(id=ignore_cpath_datasets_json, download_file=True).get()\n",
    "    with open(file.path, \"r\") as f:\n",
    "        contents = f.read()\n",
    "        content_json = json.loads(contents)\n",
    "        datasets_to_ignore = content_json.get(\"ignore_cpath_identifier\", [])\n",
    "    print(\n",
    "        \"dataset identifiers to be ignored after human review: \"\n",
    "        + str(datasets_to_ignore)\n",
    "    )\n",
    "    return datasets_to_ignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36903649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2025-10-08T23:31:33.820+0000\u001b[0m] {\u001b[34mbase.py:\u001b[0m84} INFO\u001b[0m - Retrieving connection 'SYNAPSE_ORCA_SERVICE_ACCOUNT_CONN'\u001b[0m\n",
      "[\u001b[34m2025-10-08T23:31:34.515+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: POST https://repo-prod.prod.sagebase.org/repo/v1/entity/syn68737367/bundle2 \"HTTP/1.1 200 \"\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "ifcollision=keep.both is being IGNORED because the download destination is synapse's cache. Instead, the behavior is \"overwrite.local\". \n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset identifiers to be ignored after human review: []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ignored_datasets = find_ignored_datasets(**context)\n",
    "ignored_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e83d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_existing_datasets(\n",
    "    datasets_to_update: List[Dict[str, Any]],\n",
    "    **context\n",
    ") -> List[str]:\n",
    "    \"\"\"Create new versions of existing datasets with updated annotations.\"\"\"\n",
    "\n",
    "    syn_hook = SynapseHook(context[\"params\"][\"synapse_conn_id\"])\n",
    "    updated_dataset_ids = []\n",
    "\n",
    "    for update_info in datasets_to_update:\n",
    "        item = update_info['new_data']\n",
    "        existing_id = update_info['existing_synapse_id']\n",
    "        upgrade_type = update_info['upgrade_type']\n",
    "\n",
    "        # Get existing dataset\n",
    "        existing_dataset = Dataset(id=existing_id).get()\n",
    "\n",
    "        # Update with new information\n",
    "        existing_dataset.name = item[\"title\"]\n",
    "        existing_dataset.description = (\n",
    "            item[\"description\"][:1000]\n",
    "            if len(item[\"description\"]) > 1000\n",
    "            else item[\"description\"]\n",
    "        )\n",
    "\n",
    "        # Update annotations with new data\n",
    "        existing_dataset.annotations.update({\n",
    "            \"source\": \"Critical Path Institute\",\n",
    "            \"creator\": \", \".join(item[\"creator\"]) if isinstance(item[\"creator\"], list) else item[\"creator\"],\n",
    "            \"keywords\": \", \".join(item[\"keywords\"]) if isinstance(item[\"keywords\"], list) else\n",
    "item[\"keywords\"],\n",
    "            \"subject\": \", \".join(item[\"subject\"]) if isinstance(item[\"subject\"], list) else item[\"subject\"],\n",
    "            \"collection\": \", \".join(item[\"collection\"]) if isinstance(item[\"collection\"], list) else\n",
    "item[\"collection\"],\n",
    "            \"publisher\": item[\"publisher\"],\n",
    "            \"species\": \", \".join(item[\"species\"]) if isinstance(item[\"species\"], list) else item[\"species\"],\n",
    "            \"sameAs\": item[\"sameAs\"],\n",
    "            \"url\": item[\"url\"],\n",
    "            \"contributor\": item[\"contributor\"] if isinstance(item[\"contributor\"], list) else [item[\"collection\"]]\n",
    "        })\n",
    "\n",
    "        # Store as new version\n",
    "        existing_dataset.store()\n",
    "        updated_dataset_ids.append(existing_dataset.id)\n",
    "\n",
    "        print(f\"{upgrade_type.title()} update for {item['title']}: new version {existing_dataset.version_number}\")\n",
    "\n",
    "    return updated_dataset_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02288511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2025-10-08T23:31:45.977+0000\u001b[0m] {\u001b[34mbase.py:\u001b[0m84} INFO\u001b[0m - Retrieving connection 'SYNAPSE_ORCA_SERVICE_ACCOUNT_CONN'\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handle updates first (versioning existing datasets)\n",
    "updated_ids = update_existing_datasets(datasets_to_update, **context)\n",
    "updated_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e05ff4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_datasets(\n",
    "    datasets_to_create: List[Dict[str, Any]],\n",
    "    ignored_datasets: List[str],\n",
    "    **context,\n",
    ") -> str:\n",
    "    \"\"\"Create brand new datasets for ALS numbers that don't exist yet.\"\"\"\n",
    "\n",
    "    syn_hook = SynapseHook(context[\"params\"][\"synapse_conn_id\"])\n",
    "    dataset_collection = DatasetCollection(id=context[\"params\"][\"collection_id\"]).get()\n",
    "\n",
    "    created_dataset_ids = []\n",
    "\n",
    "    for item in datasets_to_create:\n",
    "        # Skip if in ignored list\n",
    "        if item[\"sameAs\"] in ignored_datasets:\n",
    "            continue\n",
    "\n",
    "        dataset_description = (\n",
    "            item[\"description\"][:1000]\n",
    "            if len(item[\"description\"]) > 1000\n",
    "            else item[\"description\"]\n",
    "        )\n",
    "        # Set initial annotations\n",
    "        dataset_annotations = {\n",
    "            \"source\": [\"Critical Path Institute\"],\n",
    "            \"creator\": item[\"creator\"] if isinstance(item[\"creator\"], list) else [item[\"creator\"]],\n",
    "            \"keywords\": item[\"keywords\"] if isinstance(item[\"keywords\"], list) else [item[\"keywords\"]],\n",
    "            \"subject\": item[\"subject\"] if isinstance(item[\"subject\"], list) else [item[\"subject\"]],\n",
    "            \"collection\": item[\"collection\"] if isinstance(item[\"collection\"], list) else [item[\"collection\"]],\n",
    "            \"publisher\": [item[\"publisher\"]],\n",
    "            \"species\": item[\"species\"] if isinstance(item[\"species\"], list) else [item[\"species\"]],\n",
    "            \"sameAs\": [item[\"sameAs\"]],\n",
    "            \"url\": [item[\"url\"]],\n",
    "            \"title\": item[\"title\"],\n",
    "            \"contributor\": item[\"contributor\"] if isinstance(item[\"contributor\"], list) else [item[\"collection\"]]\n",
    "        }\n",
    "        # Create new dataset\n",
    "        dataset = Dataset(\n",
    "            parent_id=context[\"params\"][\"project_id\"],\n",
    "            name=item[\"title\"],\n",
    "            description=dataset_description).store()\n",
    "        dataset_collection.add_item(dataset)\n",
    "        created_dataset_ids.append(dataset.id)\n",
    "        #Storing annotations using synapseclient rather than models method cause it would not store with models method for some reason. \n",
    "        dataset_id=dataset.id\n",
    "        dataset = syn.get(dataset_id, downloadFile=False)\n",
    "        dataset.annotations=dataset_annotations\n",
    "        \n",
    "        # After store():\n",
    "        syn.store(dataset, forceVersion=False)\n",
    "        #print(dataset.annotations)\n",
    "\n",
    "\n",
    "\n",
    "        print(f\"Created new dataset: {item['title']} (ID: {dataset.id})\")\n",
    "\n",
    "    dataset_collection.store()\n",
    "    return dataset_collection.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f611ce47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2025-10-08T23:31:56.781+0000\u001b[0m] {\u001b[34mbase.py:\u001b[0m84} INFO\u001b[0m - Retrieving connection 'SYNAPSE_ORCA_SERVICE_ACCOUNT_CONN'\u001b[0m\n",
      "[\u001b[34m2025-10-08T23:31:57.244+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: POST https://repo-prod.prod.sagebase.org/repo/v1/entity/syn69962707/bundle2 \"HTTP/1.1 200 \"\u001b[0m\n",
      "[\u001b[34m2025-10-08T23:31:57.349+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: GET https://repo-prod.prod.sagebase.org/repo/v1/entity/syn69962707/column \"HTTP/1.1 200 \"\u001b[0m\n",
      "[\u001b[34m2025-10-08T23:33:11.459+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: GET https://repo-prod.prod.sagebase.org/repo/v1/column/tableview/defaults?viewEntityType=dataset&viewTypeMask=128 \"HTTP/1.1 200 \"\u001b[0m\n",
      "[\u001b[34m2025-10-08T23:33:11.673+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: POST https://repo-prod.prod.sagebase.org/repo/v1/entity/bundle2/create \"HTTP/1.1 201 \"\u001b[0m\n",
      "[\u001b[34m2025-10-08T23:33:11.759+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: POST https://repo-prod.prod.sagebase.org/repo/v1/column/batch \"HTTP/1.1 201 \"\u001b[0m\n",
      "[\u001b[34m2025-10-08T23:33:11.892+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: POST https://repo-prod.prod.sagebase.org/repo/v1/entity/syn70084694/table/transaction/async/start \"HTTP/1.1 201 \"\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0.00/1.00 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2025-10-08T23:33:11.977+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: GET https://repo-prod.prod.sagebase.org/repo/v1/entity/syn70084694/table/transaction/async/get/59389654 \"HTTP/1.1 202 \"\u001b[0m\n",
      "[\u001b[34m2025-10-08T23:33:13.103+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: GET https://repo-prod.prod.sagebase.org/repo/v1/entity/syn70084694/table/transaction/async/get/59389654 \"HTTP/1.1 201 \"\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/entity/syn70084694/table/transaction/async: 100%|██████████| 1.00/1.00 [00:01<00:00, 1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2025-10-08T23:33:13.236+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: POST https://repo-prod.prod.sagebase.org/repo/v1/entity/syn70084694/version/1/bundle2 \"HTTP/1.1 200 \"\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new dataset: A Study to Evaluate Efficacy, Safety and Tolerability of CK-2127107 in Patients With ALS (FORTITUDE-ALS) (ID: syn70084694)\n",
      "[\u001b[34m2025-10-08T23:33:14.137+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: PUT https://repo-prod.prod.sagebase.org/repo/v1/entity/syn69962707/bundle2 \"HTTP/1.1 200 \"\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Create completely new datasets\n",
    "collection_id = create_new_datasets(datasets_to_create, ignored_datasets, **context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d969cd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refresh_collection_annotations(\n",
    "    collection_id: str,\n",
    "    updated_dataset_ids: List[str],\n",
    "    **context,\n",
    ") -> None:\n",
    "    \"\"\"Refresh collection table annotations for updated datasets.\n",
    "\n",
    "    This ensures the collection table reflects the latest annotations\n",
    "    from newly versioned datasets.\n",
    "    \"\"\"\n",
    "\n",
    "    if not updated_dataset_ids:\n",
    "        print(\"No updated datasets to refresh annotations for\")\n",
    "        return\n",
    "\n",
    "    syn_hook = SynapseHook(context[\"params\"][\"synapse_conn_id\"])\n",
    "    dataset_collection = DatasetCollection(id=collection_id).get()\n",
    "\n",
    "    # Get current collection data\n",
    "    current_data = dataset_collection.query(\n",
    "        query=f\"SELECT * from {collection_id} where source='Critical Path Institute'\"\n",
    "    )\n",
    "\n",
    "    # Filter to only the datasets that were updated\n",
    "    rows_to_update = current_data[current_data['id'].isin(updated_dataset_ids)]\n",
    "\n",
    "    if rows_to_update.empty:\n",
    "        print(\"No matching rows found in collection for updated datasets\")\n",
    "        return\n",
    "\n",
    "    # For each updated dataset, get its latest annotations\n",
    "    updated_rows = []\n",
    "\n",
    "    for _, row in rows_to_update.iterrows():\n",
    "        dataset_id = row['id']\n",
    "\n",
    "        # Get the latest version of the dataset\n",
    "        dataset = Dataset(id=dataset_id).get()\n",
    "\n",
    "        # Prepare updated row data\n",
    "        updated_row = {\n",
    "            \"id\": dataset_id,\n",
    "            \"title\": dataset.name,\n",
    "            \"creator\": dataset.annotations.get(\"creator\", \"\"),\n",
    "            \"keywords\": dataset.annotations.get(\"keywords\", \"\"),\n",
    "            \"subject\": dataset.annotations.get(\"subject\", \"\"),\n",
    "            \"collection\": dataset.annotations.get(\"collection\", \"\"),\n",
    "            \"publisher\": dataset.annotations.get(\"publisher\", \"\"),\n",
    "            \"species\": dataset.annotations.get(\"species\", \"\"),\n",
    "            \"sameAs\": dataset.annotations.get(\"sameAs\", \"\"),\n",
    "            \"source\": dataset.annotations.get(\"source\", \"Critical Path Institute\"),\n",
    "            \"url\": dataset.annotations.get(\"url\", \"\"),\n",
    "            \"contributor\": dataset.annotations.get(\"contributor\")\n",
    "        }\n",
    "\n",
    "        updated_rows.append(updated_row)\n",
    "        print(f\"Refreshed annotations for {dataset.name} (version {dataset.version_number})\")\n",
    "\n",
    "    if updated_rows:\n",
    "        import pandas as pd\n",
    "        update_df = pd.DataFrame(updated_rows)\n",
    "\n",
    "        # Update the collection table\n",
    "        dataset_collection.update_rows(\n",
    "            values=update_df,\n",
    "            primary_keys=[\"id\"],\n",
    "            dry_run=False,\n",
    "            wait_for_eventually_consistent_view=True,\n",
    "        )\n",
    "\n",
    "        print(f\"Updated collection annotations for {len(updated_rows)} datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74bb295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No updated datasets to refresh annotations for\n"
     ]
    }
   ],
   "source": [
    "# Refresh collection table with latest annotations\n",
    "refresh_collection_annotations(collection_id, updated_ids, **context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295b1dc9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'params'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_cpath_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m transformed_items \u001b[38;5;241m=\u001b[39m transform_data(data)\n\u001b[1;32m      3\u001b[0m selected_items, duplicates \u001b[38;5;241m=\u001b[39m find_duplicated_datasets(transformed_items)\n",
      "Cell \u001b[0;32mIn[4], line 18\u001b[0m, in \u001b[0;36mfetch_cpath_data\u001b[0;34m(**context)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fetch data from C-Path API using auth token from Airflow Variables.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mArguments:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m    requests.exceptions.RequestException: If the API request fails\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     13\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccept\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAuthorization\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBearer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiIsImtpZCI6IjA5YWMyOTY0LTQzZTYtNDQ0ZC05MjhkLTg4ODgyYmQ5NGVjYSJ9.eyJleHAiOjE3NjE4Njg3OTksIm5iZiI6MTc1OTE4ODg0MSwiaWF0IjoxNzU5MTg4ODQxLCJzdWIiOiI2ZDFiYTNjYi02MWY5LTRhNDctYTEyYS0xMDMyMTAzZGYxYjciLCJpc3MiOiJodHRwczovL2ZhaXIuZGFwLmMtcGF0aC5vcmcvYXBpIiwiYXVkIjoiYXJpZGhpYSIsInRva2VuIjoic2FnZS1jcGF0aC1hcGktdG9rZW4ifQ.fSC-ZbL_Q7IGQwSrVR8ydYwQumM3k5f3QEm2LNK1ipM\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     16\u001b[0m }\n\u001b[0;32m---> 18\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(\u001b[43mcontext\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparams\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpath_api_url\u001b[39m\u001b[38;5;124m\"\u001b[39m], headers\u001b[38;5;241m=\u001b[39mheaders)\n\u001b[1;32m     19\u001b[0m response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "\u001b[0;31mKeyError\u001b[0m: 'params'"
     ]
    }
   ],
   "source": [
    "# Define task dependencies\n",
    "data = fetch_cpath_data()\n",
    "transformed_items = transform_data(data)\n",
    "selected_items, duplicates = find_duplicated_datasets(transformed_items)\n",
    "datasets_to_create, datasets_to_update = identify_dataset_actions(selected_items)\n",
    "ignored_datasets = find_ignored_datasets()\n",
    "\n",
    "# Handle updates first (versioning existing datasets)\n",
    "updated_ids = update_existing_datasets(datasets_to_update)\n",
    "\n",
    "# Create completely new datasets\n",
    "collection_id = create_new_datasets(datasets_to_create, ignored_datasets)\n",
    "\n",
    "# Refresh collection table with latest annotations\n",
    "refresh_collection_annotations(collection_id, updated_ids)\n",
    "\n",
    "# Slack notifications\n",
    "message = generate_slack_message(duplicates)\n",
    "post_slack_messages(message)\n",
    "\n",
    "# Set up dependencies\n",
    "transformed_items >> selected_items >> datasets_to_create\n",
    "datasets_to_create >> updated_ids >> collection_id >> refresh_collection_annotations.\n",
    "override(task_id=\"refresh_annotations\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b85fa3a",
   "metadata": {},
   "source": [
    "## dummy transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "06d7ca68",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_test_data = [\n",
    "    {\n",
    "        \"title\": \"Test ALS Dataset 1001 - FM1 Version\",\n",
    "        \"creator\": [\"Original Research Group\"],\n",
    "        \"keywords\": [\"ALS\", \"test\", \"original\"],\n",
    "        \"subject\": [\"amyotrophic lateral sclerosis\"],\n",
    "        \"description\": \"Original FM1 version for testing\",\n",
    "        \"collection\": [\"ALS Knowledge Portal\"],\n",
    "        \"publisher\": \"Critical Path Institute\",\n",
    "        \"species\": [\"Homo sapiens\"],\n",
    "        \"sameAs\": \"cpath:test1001\",\n",
    "        \"source\": \"Critical Path Institute\",\n",
    "        \"url\": \"https://fair.dap.c-path.org/#/data/datasets/fm1_als1001_2024_08_15\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Test ALS Dataset 1002 - SRC Version\",\n",
    "        \"creator\": [\"Basic Research Lab\"],\n",
    "        \"keywords\": [\"ALS\", \"preliminary\"],\n",
    "        \"subject\": [\"amyotrophic lateral sclerosis\"],\n",
    "        \"description\": \"Basic SRC version for testing\",\n",
    "        \"collection\": [\"ALS Knowledge Portal\"],\n",
    "        \"publisher\": \"Critical Path Institute\",\n",
    "        \"species\": [\"Homo sapiens\"],\n",
    "        \"sameAs\": \"cpath:test1002\",\n",
    "        \"source\": \"Critical Path Institute\",\n",
    "        \"url\": \"https://fair.dap.c-path.org/#/data/datasets/src_als1002_2024_06_10\"\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "671d11f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2025-10-03T23:52:48.432+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: POST https://repo-prod.prod.sagebase.org/repo/v1/entity/syn69962707/bundle2 \"HTTP/1.1 200 \"\u001b[0m\n",
      "[\u001b[34m2025-10-03T23:52:48.542+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: GET https://repo-prod.prod.sagebase.org/repo/v1/entity/syn69962707/column \"HTTP/1.1 200 \"\u001b[0m\n",
      "[\u001b[34m2025-10-03T23:52:50.339+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: GET https://repo-prod.prod.sagebase.org/repo/v1/column/tableview/defaults?viewEntityType=dataset&viewTypeMask=128 \"HTTP/1.1 200 \"\u001b[0m\n",
      "[\u001b[34m2025-10-03T23:52:50.512+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: POST https://repo-prod.prod.sagebase.org/repo/v1/entity/bundle2/create \"HTTP/1.1 201 \"\u001b[0m\n",
      "[\u001b[34m2025-10-03T23:52:50.630+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: POST https://repo-prod.prod.sagebase.org/repo/v1/column/batch \"HTTP/1.1 201 \"\u001b[0m\n",
      "[\u001b[34m2025-10-03T23:52:50.742+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: POST https://repo-prod.prod.sagebase.org/repo/v1/entity/syn69981986/table/transaction/async/start \"HTTP/1.1 201 \"\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2025-10-03T23:52:50.852+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: GET https://repo-prod.prod.sagebase.org/repo/v1/entity/syn69981986/table/transaction/async/get/59100202 \"HTTP/1.1 202 \"\u001b[0m\n",
      "[\u001b[34m2025-10-03T23:52:51.935+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: GET https://repo-prod.prod.sagebase.org/repo/v1/entity/syn69981986/table/transaction/async/get/59100202 \"HTTP/1.1 201 \"\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2025-10-03T23:52:52.084+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: POST https://repo-prod.prod.sagebase.org/repo/v1/entity/syn69981986/version/1/bundle2 \"HTTP/1.1 200 \"\u001b[0m\n",
      "[\u001b[34m2025-10-03T23:52:53.245+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: GET https://repo-prod.prod.sagebase.org/repo/v1/column/tableview/defaults?viewEntityType=dataset&viewTypeMask=128 \"HTTP/1.1 200 \"\u001b[0m\n",
      "[\u001b[34m2025-10-03T23:52:53.411+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: POST https://repo-prod.prod.sagebase.org/repo/v1/entity/bundle2/create \"HTTP/1.1 201 \"\u001b[0m\n",
      "[\u001b[34m2025-10-03T23:52:53.506+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: POST https://repo-prod.prod.sagebase.org/repo/v1/column/batch \"HTTP/1.1 201 \"\u001b[0m\n",
      "[\u001b[34m2025-10-03T23:52:53.628+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: POST https://repo-prod.prod.sagebase.org/repo/v1/entity/syn69981987/table/transaction/async/start \"HTTP/1.1 201 \"\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2025-10-03T23:52:53.736+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: GET https://repo-prod.prod.sagebase.org/repo/v1/entity/syn69981987/table/transaction/async/get/59100203 \"HTTP/1.1 202 \"\u001b[0m\n",
      "[\u001b[34m2025-10-03T23:52:54.829+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: GET https://repo-prod.prod.sagebase.org/repo/v1/entity/syn69981987/table/transaction/async/get/59100203 \"HTTP/1.1 201 \"\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2025-10-03T23:52:54.981+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: POST https://repo-prod.prod.sagebase.org/repo/v1/entity/syn69981987/version/1/bundle2 \"HTTP/1.1 200 \"\u001b[0m\n",
      "[\u001b[34m2025-10-03T23:52:55.820+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: PUT https://repo-prod.prod.sagebase.org/repo/v1/entity/syn69962707/bundle2 \"HTTP/1.1 200 \"\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetCollection(id='syn69962707', name='Cpath-Dataset-Collection-Test', parent_id='syn64892175', activity=None, version_number=1, _columns_to_delete={}, view_entity_type=<ViewEntityType.DATASET_COLLECTION: 'datasetcollection'>, view_type_mask=<ViewTypeMask.DATASET_COLLECTION: 256>, include_default_columns=True, description='', etag='ce8825fd-4f00-4081-9b58-366da5f76baa', created_on='2025-09-30T18:20:42.333Z', modified_on='2025-10-03T23:52:55.705Z', created_by='3436666', modified_by='3436666', version_label='1', version_comment=None, is_latest_version=True, is_search_enabled=False, items=[EntityRef(id='syn66496325', version=1), EntityRef(id='syn66496324', version=1), EntityRef(id='syn69966250', version=1), EntityRef(id='syn69966251', version=1), EntityRef(id='syn69981986', version=1), EntityRef(id='syn69981987', version=1)], columns=OrderedDict([('id', Column(id='81721', name='id', column_type=ENTITYID, facet_type=None, default_value=None, maximum_size=None, maximum_list_length=None, enum_values=None, json_sub_columns=None)), ('name', Column(id='81722', name='name', column_type=STRING, facet_type=None, default_value=None, maximum_size=256, maximum_list_length=None, enum_values=None, json_sub_columns=None)), ('description', Column(id='87941', name='description', column_type=STRING, facet_type=None, default_value=None, maximum_size=1000, maximum_list_length=None, enum_values=None, json_sub_columns=None)), ('createdOn', Column(id='81723', name='createdOn', column_type=DATE, facet_type=<FacetType.RANGE: 'range'>, default_value=None, maximum_size=None, maximum_list_length=None, enum_values=None, json_sub_columns=None)), ('createdBy', Column(id='81724', name='createdBy', column_type=USERID, facet_type=<FacetType.ENUMERATION: 'enumeration'>, default_value=None, maximum_size=None, maximum_list_length=None, enum_values=None, json_sub_columns=None)), ('etag', Column(id='81725', name='etag', column_type=STRING, facet_type=None, default_value=None, maximum_size=36, maximum_list_length=None, enum_values=None, json_sub_columns=None)), ('modifiedOn', Column(id='81726', name='modifiedOn', column_type=DATE, facet_type=<FacetType.RANGE: 'range'>, default_value=None, maximum_size=None, maximum_list_length=None, enum_values=None, json_sub_columns=None)), ('modifiedBy', Column(id='81727', name='modifiedBy', column_type=USERID, facet_type=<FacetType.ENUMERATION: 'enumeration'>, default_value=None, maximum_size=None, maximum_list_length=None, enum_values=None, json_sub_columns=None)), ('path', Column(id='214396', name='path', column_type=STRING, facet_type=None, default_value=None, maximum_size=1000, maximum_list_length=None, enum_values=None, json_sub_columns=None)), ('datasetSizeInBytes', Column(id='188774', name='datasetSizeInBytes', column_type=INTEGER, facet_type=None, default_value=None, maximum_size=None, maximum_list_length=None, enum_values=None, json_sub_columns=None)), ('datasetMD5Hex', Column(id='188775', name='datasetMD5Hex', column_type=STRING, facet_type=None, default_value=None, maximum_size=100, maximum_list_length=None, enum_values=None, json_sub_columns=None)), ('datasetItemCount', Column(id='187841', name='datasetItemCount', column_type=INTEGER, facet_type=None, default_value=None, maximum_size=None, maximum_list_length=None, enum_values=None, json_sub_columns=None)), ('collection', Column(id='244003', name='collection', column_type=STRING, facet_type=<FacetType.ENUMERATION: 'enumeration'>, default_value=None, maximum_size=24, maximum_list_length=None, enum_values=None, json_sub_columns=None)), ('creator', Column(id='244004', name='creator', column_type=STRING, facet_type=<FacetType.ENUMERATION: 'enumeration'>, default_value=None, maximum_size=60, maximum_list_length=None, enum_values=None, json_sub_columns=None)), ('keywords', Column(id='244001', name='keywords', column_type=STRING_LIST, facet_type=<FacetType.ENUMERATION: 'enumeration'>, default_value=None, maximum_size=43, maximum_list_length=9, enum_values=None, json_sub_columns=None)), ('publisher', Column(id='244005', name='publisher', column_type=STRING, facet_type=<FacetType.ENUMERATION: 'enumeration'>, default_value=None, maximum_size=27, maximum_list_length=None, enum_values=None, json_sub_columns=None)), ('sameAs', Column(id='244006', name='sameAs', column_type=STRING, facet_type=<FacetType.ENUMERATION: 'enumeration'>, default_value=None, maximum_size=21, maximum_list_length=None, enum_values=None, json_sub_columns=None)), ('source', Column(id='244007', name='source', column_type=STRING, facet_type=<FacetType.ENUMERATION: 'enumeration'>, default_value=None, maximum_size=27, maximum_list_length=None, enum_values=None, json_sub_columns=None)), ('species', Column(id='244008', name='species', column_type=STRING, facet_type=<FacetType.ENUMERATION: 'enumeration'>, default_value=None, maximum_size=16, maximum_list_length=None, enum_values=None, json_sub_columns=None)), ('subject', Column(id='244009', name='subject', column_type=STRING, facet_type=<FacetType.ENUMERATION: 'enumeration'>, default_value=None, maximum_size=33, maximum_list_length=None, enum_values=None, json_sub_columns=None)), ('title', Column(id='243884', name='title', column_type=STRING, facet_type=<FacetType.ENUMERATION: 'enumeration'>, default_value=None, maximum_size=115, maximum_list_length=None, enum_values=None, json_sub_columns=None)), ('url', Column(id='244010', name='url', column_type=STRING, facet_type=<FacetType.ENUMERATION: 'enumeration'>, default_value=None, maximum_size=70, maximum_list_length=None, enum_values=None, json_sub_columns=None))]), annotations={})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_collection = DatasetCollection(id=context[\"params\"][\"collection_id\"]).get()\n",
    "for test_dataset in initial_test_data: \n",
    "    dataset = Dataset(\n",
    "        parent_id=context[\"params\"][\"project_id\"],\n",
    "        name=test_dataset[\"title\"],\n",
    "        description=test_dataset[\"description\"],   \n",
    "    ).store()\n",
    "    dataset_collection.add_item(dataset)\n",
    "    dataset_id=dataset.id\n",
    "    dataset=syn.get(dataset_id, downloadFile=False)\n",
    "    dataset.annotations=test_dataset\n",
    "    syn.store(dataset, forceVersion=False)\n",
    "dataset_collection.store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ae336954",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_items = [\n",
    "    # Scenario 1: Version upgrade (fm1 → fv1)\n",
    "    {\n",
    "        \"title\": \"Test ALS Dataset 1001 - FV1 Upgrade\",\n",
    "        \"creator\": [\"Upgraded Research Group\", \"New Collaborator\"],\n",
    "        \"keywords\": [\"ALS\", \"test\", \"standardized\", \"validated\"],\n",
    "        \"subject\": [\"amyotrophic lateral sclerosis\"],\n",
    "        \"description\": \"Upgraded FV1 version with standardized data\",\n",
    "        \"collection\": [\"ALS Knowledge Portal\"],\n",
    "        \"publisher\": \"Critical Path Institute\",\n",
    "        \"species\": [\"Homo sapiens\"],\n",
    "        \"sameAs\": \"cpath:test1001_v2\",\n",
    "        \"source\": \"Critical Path Institute\",\n",
    "        \"url\": \"https://fair.dap.c-path.org/#/data/datasets/fv1_als1001_2025_01_20\"\n",
    "    },\n",
    "\n",
    "    # Scenario 2: Version upgrade (src → fm2)\n",
    "    {\n",
    "        \"title\": \"Test ALS Dataset 1002 - FM2 Upgrade\",\n",
    "        \"creator\": [\"Enhanced Research Lab\"],\n",
    "        \"keywords\": [\"ALS\", \"enhanced\", \"non-standardized\"],\n",
    "        \"subject\": [\"amyotrophic lateral sclerosis\"],\n",
    "        \"description\": \"Enhanced FM2 version with more data\",\n",
    "        \"collection\": [\"ALS Knowledge Portal\"],\n",
    "        \"publisher\": \"Critical Path Institute\",\n",
    "        \"species\": [\"Homo sapiens\"],\n",
    "        \"sameAs\": \"cpath:test1002_v2\",\n",
    "        \"source\": \"Critical Path Institute\",\n",
    "        \"url\": \"https://fair.dap.c-path.org/#/data/datasets/fm2_als1002_2024_12_01\"\n",
    "    },\n",
    "\n",
    "    # Scenario 3: Same version, newer date (annotation update)\n",
    "    {\n",
    "        \"title\": \"Test ALS Dataset 1001 - FV1 Updated Annotations\",\n",
    "        \"creator\": [\"Upgraded Research Group\", \"New Collaborator\", \"Additional PI\"],\n",
    "        \"keywords\": [\"ALS\", \"test\", \"standardized\", \"validated\", \"updated\"],\n",
    "        \"subject\": [\"amyotrophic lateral sclerosis\"],\n",
    "        \"description\": \"Same FV1 version but with updated metadata and annotations\",\n",
    "        \"collection\": [\"ALS Knowledge Portal\"],\n",
    "        \"publisher\": \"Critical Path Institute\",\n",
    "        \"species\": [\"Homo sapiens\"],\n",
    "        \"sameAs\": \"cpath:test1001_v3\",\n",
    "        \"source\": \"Critical Path Institute\",\n",
    "        \"url\": \"https://fair.dap.c-path.org/#/data/datasets/fv1_als1001_2025_02_15\"  # Newer date\n",
    "    },\n",
    "\n",
    "    # Scenario 4: Completely new ALS number\n",
    "    {\n",
    "        \"title\": \"Test ALS Dataset 1003 - New Dataset\",\n",
    "        \"creator\": [\"New Research Institute\"],\n",
    "        \"keywords\": [\"ALS\", \"novel\", \"experimental\"],\n",
    "        \"subject\": [\"amyotrophic lateral sclerosis\"],\n",
    "        \"description\": \"Brand new ALS dataset for testing\",\n",
    "        \"collection\": [\"ALS Knowledge Portal\"],\n",
    "        \"publisher\": \"Critical Path Institute\",\n",
    "        \"species\": [\"Homo sapiens\"],\n",
    "        \"sameAs\": \"cpath:test1003\",\n",
    "        \"source\": \"Critical Path Institute\",\n",
    "        \"url\": \"https://fair.dap.c-path.org/#/data/datasets/fv3_als1003_2025_03_01\"\n",
    "    },\n",
    "\n",
    "    # Scenario 5: Lower priority version (should be ignored)\n",
    "    {\n",
    "        \"title\": \"Test ALS Dataset 1001 - FM2 Lower Priority\",\n",
    "        \"creator\": [\"Lower Priority Group\"],\n",
    "        \"keywords\": [\"ALS\", \"lower\"],\n",
    "        \"subject\": [\"amyotrophic lateral sclerosis\"],\n",
    "        \"description\": \"Lower priority version that should be ignored\",\n",
    "        \"collection\": [\"ALS Knowledge Portal\"],\n",
    "        \"publisher\": \"Critical Path Institute\",\n",
    "        \"species\": [\"Homo sapiens\"],\n",
    "        \"sameAs\": \"cpath:test1001_low\",\n",
    "        \"source\": \"Critical Path Institute\",\n",
    "        \"url\": \"https://fair.dap.c-path.org/#/data/datasets/fm2_als1001_2025_03_01\"  # fm2 < fv1\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "14774340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2025-10-03T23:53:02.458+0000\u001b[0m] {\u001b[34mbase.py:\u001b[0m84} INFO\u001b[0m - Retrieving connection 'SYNAPSE_ORCA_SERVICE_ACCOUNT_CONN'\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2025-10-03T23:53:08.436+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: POST https://file-prod.prod.sagebase.org/file/v1/fileHandle/batch \"HTTP/1.1 201 \"\u001b[0m\n",
      "Found 5 new items to process from 5 total items\n",
      "Selected fv1_als1001_2025_02_15 for als1001 (priority: 4, date: 2025_02_15)\n",
      "Selected fm2_als1002_2024_12_01 for als1002 (priority: 3, date: 2024_12_01)\n",
      "Selected fv3_als1003_2025_03_01 for als1003 (priority: 6, date: 2025_03_01)\n",
      "Selected 3 datasets from 5 new items\n",
      "[\u001b[34m2025-10-03T23:53:08.696+0000\u001b[0m] {\u001b[34mbase.py:\u001b[0m84} INFO\u001b[0m - Retrieving connection 'SYNAPSE_ORCA_SERVICE_ACCOUNT_CONN'\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2025-10-03T23:53:10.971+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: POST https://file-prod.prod.sagebase.org/file/v1/fileHandle/batch \"HTTP/1.1 201 \"\u001b[0m\n",
      "Will update fm1_als1001_2024_08_15 -> fv1_als1001_2025_02_15 (version)\n",
      "Will update src_als1002_2024_06_10 -> fm2_als1002_2024_12_01 (version)\n",
      "Will update fv2_als1003_2025_04_28 -> fv3_als1003_2025_03_01 (version)\n",
      "[\u001b[34m2025-10-03T23:53:11.251+0000\u001b[0m] {\u001b[34mbase.py:\u001b[0m84} INFO\u001b[0m - Retrieving connection 'SYNAPSE_ORCA_SERVICE_ACCOUNT_CONN'\u001b[0m\n",
      "[\u001b[34m2025-10-03T23:53:12.038+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: POST https://repo-prod.prod.sagebase.org/repo/v1/entity/syn68737367/bundle2 \"HTTP/1.1 200 \"\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "ifcollision=keep.both is being IGNORED because the download destination is synapse's cache. Instead, the behavior is \"overwrite.local\". \n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset identifiers to be ignored after human review: []\n",
      "[\u001b[34m2025-10-03T23:53:12.043+0000\u001b[0m] {\u001b[34mbase.py:\u001b[0m84} INFO\u001b[0m - Retrieving connection 'SYNAPSE_ORCA_SERVICE_ACCOUNT_CONN'\u001b[0m\n",
      "[\u001b[34m2025-10-03T23:53:12.183+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: POST https://repo-prod.prod.sagebase.org/repo/v1/entity/syn69981986/bundle2 \"HTTP/1.1 200 \"\u001b[0m\n",
      "[\u001b[34m2025-10-03T23:53:12.277+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: GET https://repo-prod.prod.sagebase.org/repo/v1/entity/syn69981986/column \"HTTP/1.1 200 \"\u001b[0m\n",
      "[\u001b[34m2025-10-03T23:53:12.512+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: PUT https://repo-prod.prod.sagebase.org/repo/v1/entity/syn69981986/bundle2 \"HTTP/1.1 200 \"\u001b[0m\n",
      "[\u001b[34m2025-10-03T23:53:12.636+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: PUT https://repo-prod.prod.sagebase.org/repo/v1/entity/syn69981986/annotations2 \"HTTP/1.1 200 \"\u001b[0m\n",
      "Version update for Test ALS Dataset 1001 - FV1 Updated Annotations: new version 1\n",
      "[\u001b[34m2025-10-03T23:53:12.773+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: POST https://repo-prod.prod.sagebase.org/repo/v1/entity/syn69981987/bundle2 \"HTTP/1.1 200 \"\u001b[0m\n",
      "[\u001b[34m2025-10-03T23:53:12.886+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: GET https://repo-prod.prod.sagebase.org/repo/v1/entity/syn69981987/column \"HTTP/1.1 200 \"\u001b[0m\n",
      "[\u001b[34m2025-10-03T23:53:13.097+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: PUT https://repo-prod.prod.sagebase.org/repo/v1/entity/syn69981987/bundle2 \"HTTP/1.1 200 \"\u001b[0m\n",
      "[\u001b[34m2025-10-03T23:53:13.219+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: PUT https://repo-prod.prod.sagebase.org/repo/v1/entity/syn69981987/annotations2 \"HTTP/1.1 200 \"\u001b[0m\n",
      "Version update for Test ALS Dataset 1002 - FM2 Upgrade: new version 1\n",
      "[\u001b[34m2025-10-03T23:53:13.340+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: POST https://repo-prod.prod.sagebase.org/repo/v1/entity/syn69966251/bundle2 \"HTTP/1.1 200 \"\u001b[0m\n",
      "[\u001b[34m2025-10-03T23:53:13.442+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: GET https://repo-prod.prod.sagebase.org/repo/v1/entity/syn69966251/column \"HTTP/1.1 200 \"\u001b[0m\n",
      "[\u001b[34m2025-10-03T23:53:13.636+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: PUT https://repo-prod.prod.sagebase.org/repo/v1/entity/syn69966251/bundle2 \"HTTP/1.1 200 \"\u001b[0m\n",
      "[\u001b[34m2025-10-03T23:53:13.779+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: PUT https://repo-prod.prod.sagebase.org/repo/v1/entity/syn69966251/annotations2 \"HTTP/1.1 200 \"\u001b[0m\n",
      "Version update for Test ALS Dataset 1003 - New Dataset: new version 1\n",
      "[\u001b[34m2025-10-03T23:53:13.782+0000\u001b[0m] {\u001b[34mbase.py:\u001b[0m84} INFO\u001b[0m - Retrieving connection 'SYNAPSE_ORCA_SERVICE_ACCOUNT_CONN'\u001b[0m\n",
      "[\u001b[34m2025-10-03T23:53:13.928+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: POST https://repo-prod.prod.sagebase.org/repo/v1/entity/syn69962707/bundle2 \"HTTP/1.1 200 \"\u001b[0m\n",
      "[\u001b[34m2025-10-03T23:53:14.028+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: GET https://repo-prod.prod.sagebase.org/repo/v1/entity/syn69962707/column \"HTTP/1.1 200 \"\u001b[0m\n",
      "[\u001b[34m2025-10-03T23:53:14.031+0000\u001b[0m] {\u001b[34mbase.py:\u001b[0m84} INFO\u001b[0m - Retrieving connection 'SYNAPSE_ORCA_SERVICE_ACCOUNT_CONN'\u001b[0m\n",
      "[\u001b[34m2025-10-03T23:53:14.148+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: POST https://repo-prod.prod.sagebase.org/repo/v1/entity/syn69962707/bundle2 \"HTTP/1.1 200 \"\u001b[0m\n",
      "[\u001b[34m2025-10-03T23:53:14.246+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: GET https://repo-prod.prod.sagebase.org/repo/v1/entity/syn69962707/column \"HTTP/1.1 200 \"\u001b[0m\n",
      "[\u001b[34m2025-10-03T23:53:15.976+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: POST https://repo-prod.prod.sagebase.org/repo/v1/entity/syn69966251/bundle2 \"HTTP/1.1 200 \"\u001b[0m\n",
      "[\u001b[34m2025-10-03T23:53:16.075+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: GET https://repo-prod.prod.sagebase.org/repo/v1/entity/syn69966251/column \"HTTP/1.1 200 \"\u001b[0m\n",
      "Refreshed annotations for Test ALS Dataset 1003 - New Dataset (version 1)\n",
      "[\u001b[34m2025-10-03T23:53:16.213+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: POST https://repo-prod.prod.sagebase.org/repo/v1/entity/syn69981986/bundle2 \"HTTP/1.1 200 \"\u001b[0m\n",
      "[\u001b[34m2025-10-03T23:53:16.312+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: GET https://repo-prod.prod.sagebase.org/repo/v1/entity/syn69981986/column \"HTTP/1.1 200 \"\u001b[0m\n",
      "Refreshed annotations for Test ALS Dataset 1001 - FV1 Updated Annotations (version 1)\n",
      "[\u001b[34m2025-10-03T23:53:16.438+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: POST https://repo-prod.prod.sagebase.org/repo/v1/entity/syn69981987/bundle2 \"HTTP/1.1 200 \"\u001b[0m\n",
      "[\u001b[34m2025-10-03T23:53:16.535+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: GET https://repo-prod.prod.sagebase.org/repo/v1/entity/syn69981987/column \"HTTP/1.1 200 \"\u001b[0m\n",
      "Refreshed annotations for Test ALS Dataset 1002 - FM2 Upgrade (version 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2025-10-03T23:53:18.430+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: POST https://repo-prod.prod.sagebase.org/repo/v1/entity/syn69962707/table/transaction/async/start \"HTTP/1.1 201 \"\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2025-10-03T23:53:18.528+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: GET https://repo-prod.prod.sagebase.org/repo/v1/entity/syn69962707/table/transaction/async/get/59100229 \"HTTP/1.1 202 \"\u001b[0m\n",
      "[\u001b[34m2025-10-03T23:53:19.622+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1773} INFO\u001b[0m - HTTP Request: GET https://repo-prod.prod.sagebase.org/repo/v1/entity/syn69962707/table/transaction/async/get/59100229 \"HTTP/1.1 201 \"\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Querying & Updating rows: 100%|██████████| 3.00/3.00 [00:03<00:00, 1.03s/it]\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Waiting for eventually-consistent changes to show up in the view: 100%|██████████| 3.00/3.00 [00:00<00:00, 3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated collection annotations for 3 datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "selected_items, duplicates = find_duplicated_datasets(transformed_items,**context)\n",
    "datasets_to_create, datasets_to_update = identify_dataset_actions(selected_items, **context)\n",
    "ignored_datasets = find_ignored_datasets(**context)\n",
    "\n",
    "# Handle updates first (versioning existing datasets)\n",
    "updated_ids = update_existing_datasets(datasets_to_update, **context)\n",
    "\n",
    "# Create completely new datasets\n",
    "collection_id = create_new_datasets(datasets_to_create, ignored_datasets, **context)\n",
    "\n",
    "# Refresh collection table with latest annotations\n",
    "refresh_collection_annotations(collection_id, updated_ids, **context)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
